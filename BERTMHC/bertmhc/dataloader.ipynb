{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader de BERTMHC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este script, se detalla el dataloader para preparar el training set. EL training set de ejemplo esta en el archivo train_old.csv\n",
    "De dicho archivo, se utiliza la columna 'mhc' y 'peptide' concatenadas como input y el target esta compuesto por las columnas 'label' y 'masslabel'. Tambien se utiliza un la función collate_fn de pytorch para asegurar el mismo tamaño de los inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicente/anaconda3/envs/torch11/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "__main__ - Training on 107424 samples, eval on 13428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([ 2, 20,  9, 10, 10, 13,  5, 22, 11,  5,  5, 25,  8,  5, 13, 16,  9,\n",
      "       22, 22, 10,  8, 28, 10,  8, 13,  8,  9,  5, 23, 28, 12, 25, 25, 10,\n",
      "       23, 23, 13, 19, 15, 25,  5, 15, 23, 15, 23, 22, 28, 15, 11, 15, 14,\n",
      "       27, 27, 27, 27, 27, 27, 27, 27,  3]), 'input_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'targets': array([0.698876, 1.      ])}\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Union, List, Tuple, Sequence, Dict, Any, Optional, Collection, Mapping\n",
    "from pathlib import Path\n",
    "from tape.tokenizers import TAPETokenizer\n",
    "from tape.datasets import pad_sequences as tape_pad\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from bertmhc import BERTMHC, BERTMHC_CNN\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils_model import EarlyStopping\n",
    "from utils_model import train, evaluate\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_file: Union[str, Path, pd.DataFrame],\n",
    "                 max_pep_len=60,\n",
    "                 train: bool = True):\n",
    "        if isinstance(data_file, pd.DataFrame):\n",
    "            data = data_file\n",
    "        else:\n",
    "            data = pd.read_csv(data_file)\n",
    "        mhc = data['mhc']\n",
    "        self.mhc = mhc.values\n",
    "        peptide = data['peptide']\n",
    "        peptide = peptide.apply(lambda x: x[:max_pep_len])\n",
    "        self.peptide = peptide.values\n",
    "        if not train:\n",
    "            data['label'] = np.nan\n",
    "            data['masslabel'] = np.nan\n",
    "        if 'masslabel' not in data and 'label' not in data:\n",
    "            raise ValueError(\"missing label.\")\n",
    "        if 'masslabel' not in data:\n",
    "            data['masslabel'] = np.nan\n",
    "        if 'label' not in data:\n",
    "            data['label'] = np.nan\n",
    "\n",
    "        ###########################################################################################################\n",
    "        ##### el target esta compuesto por el label(float) y masslabel(int) #######################################\n",
    "        self.targets = np.stack([data['label'], data['masslabel']], axis=1)\n",
    "        self.data = data        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.mhc)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        ###########################################################################################################\n",
    "        ##### aqui concatena el MHC con el peptido para que todo eso sea el input #################################\n",
    "        seq = self.mhc[index] + self.peptide[index]\n",
    "        \n",
    "        # aqui hacemos padding y reemplazamos algunos aminoacidos\n",
    "        seq = seq + 'X' * (58 - len(seq)) \n",
    "        seq = re.sub(r\"[UZOBJ]\", \"X\", seq).upper()\n",
    "        \n",
    "        return {\n",
    "            \"id\": str(index),\n",
    "            \"primary\": seq,\n",
    "            \"protein_length\": len(seq),\n",
    "            \"targets\": self.targets[index]}\n",
    "    \n",
    "\n",
    "\n",
    "class BertDataset(Dataset):\n",
    "    ''' Load data for pretrained Bert model, implemented in TAPE\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_file,\n",
    "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
    "                 max_pep_len=30,\n",
    "                 train: bool = True):\n",
    "        if isinstance(tokenizer, str):\n",
    "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = CSVDataset(input_file,\n",
    "                               max_pep_len=max_pep_len,\n",
    "                               train=train)        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        item = self.data[index]\n",
    "        \n",
    "        token_ids = self.tokenizer.encode(item['primary'])\n",
    "        input_mask = np.ones_like(token_ids)\n",
    "        ret = {'input_ids': token_ids,\n",
    "               'input_mask': input_mask,\n",
    "               'targets': item['targets']}\n",
    "        \n",
    "        return ret\n",
    "\n",
    "    def collate_fn(self, batch) -> Dict[str, torch.Tensor]:\n",
    "        elem = batch[0]\n",
    "        batch = {key: [d[key] for d in batch] for key in elem}\n",
    "        input_ids = torch.from_numpy(tape_pad(batch['input_ids'], 0))\n",
    "        input_mask = torch.from_numpy(tape_pad(batch['input_mask'], 0))\n",
    "        tmp = np.array(batch['targets'])\n",
    "        #targets = torch.tensor(batch['targets'], dtype=torch.float32)\n",
    "        targets = torch.tensor(tmp, dtype=torch.float32)\n",
    "        ret = {'input_ids': input_ids,\n",
    "               'input_mask': input_mask,\n",
    "               'targets': targets}\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "# dataset\n",
    "trainset = BertDataset('../../dataset/netMHCIIpan3.2/train_mini.csv', max_pep_len=24)\n",
    "valset = BertDataset('../../dataset/netMHCIIpan3.2/eval_mini.csv', max_pep_len=24)\n",
    "first_sample = trainset[0] \n",
    "#print(first_sample['input_ids']) # indices del one-hot encoding\n",
    "#print(first_sample['input_mask'])\n",
    "#print(first_sample['targets']) \n",
    "print(first_sample)\n",
    "print(first_sample['input_ids'].shape)\n",
    "\n",
    "logging.basicConfig(format='%(name)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "train_data = DataLoader(        trainset,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                num_workers=16,\n",
    "                                pin_memory=True,\n",
    "                                collate_fn=trainset.collate_fn)\n",
    "\n",
    "val_data = DataLoader(        valset,\n",
    "                              batch_size=64,\n",
    "                              num_workers=16,\n",
    "                              pin_memory=True,\n",
    "                              collate_fn=valset.collate_fn)\n",
    "\n",
    "logger.info(\"Training on {0} samples, eval on {1}\".format(len(trainset), len(valset)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTMHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n",
      "\n",
      "Cargamos los pesos de TAPE\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tape.models.modeling_utils - loading configuration file https://s3.amazonaws.com/songlabdata/proteindata/pytorch-models/bert-base-config.json from cache at /home/vicente/.cache/torch/protein_models/fbb05edff0ffa844a729a04850272a1f8973bc002526f6615ad113a5f5aacd36.05edb4ed225e1907a3878f9d68b275d79e025b667555aa94a086e27cb5c591e0\n",
      "tape.models.modeling_utils - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"base_model\": \"transformer\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"input_size\": 768,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_size\": 768,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 30\n",
      "}\n",
      "\n",
      "tape.models.modeling_utils - loading weights file https://s3.amazonaws.com/songlabdata/proteindata/pytorch-models/bert-base-pytorch_model.bin from cache at /home/vicente/.cache/torch/protein_models/2ed84d28db0a61af4cd2dd3f2ccdd3ee45b1533547a8e1213840af895e2fa8d1.8206daaea9be2736b6ccde432df9dc3dbb8c3233b47f07688d6ff38d74258d22\n",
      "tape.models.modeling_utils - Weights of BERTMHC not initialized from pretrained model: ['classify.classify.main.0.bias', 'classify.classify.main.0.weight_g', 'classify.classify.main.0.weight_v', 'classify.classify.main.3.bias', 'classify.classify.main.3.weight_g', 'classify.classify.main.3.weight_v']\n",
      "tape.models.modeling_utils - Weights from pretrained model not used in BERTMHC: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTMHC(\n",
      "  (bert): ProteinBertModel(\n",
      "    (embeddings): ProteinBertEmbeddings(\n",
      "      (word_embeddings): Embedding(30, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(8192, 768)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ProteinBertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): ProteinBertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classify): MHCHead(\n",
      "    (classify): SimpleMLP(\n",
      "      (main): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=True)\n",
      "        (3): Linear(in_features=512, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "print(\"\\nCargamos los pesos de TAPE\\n\\n\")\n",
    "model = BERTMHC.from_pretrained('bert-base')\n",
    "\n",
    "for p in model.bert.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametros de BERTMHC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPE tiene 92356612 parametros <br>\n",
    "ProtTrans (prot_bert_bfd) tiene 419933186 (4x larger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 92356612\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"params:\", pytorch_total_params)\n",
    "\n",
    "#from torchvision import models\n",
    "#from torchsummary import summary\n",
    "#summary(model, (60, 768))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTMHC CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n",
      "\n",
      "Cargamos los pesos de TAPE\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tape.models.modeling_utils - loading configuration file https://s3.amazonaws.com/songlabdata/proteindata/pytorch-models/bert-base-config.json from cache at /home/vicente/.cache/torch/protein_models/fbb05edff0ffa844a729a04850272a1f8973bc002526f6615ad113a5f5aacd36.05edb4ed225e1907a3878f9d68b275d79e025b667555aa94a086e27cb5c591e0\n",
      "tape.models.modeling_utils - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"base_model\": \"transformer\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"input_size\": 768,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_size\": 768,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 30\n",
      "}\n",
      "\n",
      "tape.models.modeling_utils - loading weights file https://s3.amazonaws.com/songlabdata/proteindata/pytorch-models/bert-base-pytorch_model.bin from cache at /home/vicente/.cache/torch/protein_models/2ed84d28db0a61af4cd2dd3f2ccdd3ee45b1533547a8e1213840af895e2fa8d1.8206daaea9be2736b6ccde432df9dc3dbb8c3233b47f07688d6ff38d74258d22\n",
      "tape.models.modeling_utils - Weights of BERTMHC_CNN not initialized from pretrained model: ['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
      "tape.models.modeling_utils - Weights from pretrained model not used in BERTMHC_CNN: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTMHC_CNN(\n",
      "  (bert): ProteinBertModel(\n",
      "    (embeddings): ProteinBertEmbeddings(\n",
      "      (word_embeddings): Embedding(30, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(8192, 768)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ProteinBertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ProteinBertLayer(\n",
      "          (attention): ProteinBertAttention(\n",
      "            (self): ProteinBertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ProteinBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ProteinBertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ProteinBertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): ProteinBertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=36288, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "print(\"\\nCargamos los pesos de TAPE\\n\\n\")\n",
    "model = BERTMHC_CNN.from_pretrained('bert-base')\n",
    "\n",
    "for p in model.bert.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTMHC Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tape.models.modeling_utils - loading configuration file https://s3.amazonaws.com/songlabdata/proteindata/pytorch-models/bert-base-config.json from cache at /home/vicente/.cache/torch/protein_models/fbb05edff0ffa844a729a04850272a1f8973bc002526f6615ad113a5f5aacd36.05edb4ed225e1907a3878f9d68b275d79e025b667555aa94a086e27cb5c591e0\n",
      "tape.models.modeling_utils - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"base_model\": \"transformer\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"input_size\": 768,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_size\": 768,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 30\n",
      "}\n",
      "\n",
      "tape.models.modeling_utils - loading weights file https://s3.amazonaws.com/songlabdata/proteindata/pytorch-models/bert-base-pytorch_model.bin from cache at /home/vicente/.cache/torch/protein_models/2ed84d28db0a61af4cd2dd3f2ccdd3ee45b1533547a8e1213840af895e2fa8d1.8206daaea9be2736b6ccde432df9dc3dbb8c3233b47f07688d6ff38d74258d22\n",
      "tape.models.modeling_utils - Weights of BERTMHC not initialized from pretrained model: ['classify.classify.main.0.bias', 'classify.classify.main.0.weight_g', 'classify.classify.main.0.weight_v', 'classify.classify.main.3.bias', 'classify.classify.main.3.weight_g', 'classify.classify.main.3.weight_v']\n",
      "tape.models.modeling_utils - Weights from pretrained model not used in BERTMHC: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n"
     ]
    }
   ],
   "source": [
    "from bertmhc import BERTMHC_LINEAR, BERTMHC\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "#model = BERTMHC_LINEAR.from_pretrained('bert-base')\n",
    "model = BERTMHC_LINEAR.from_pretrained('bert-base')\n",
    "\n",
    "for p in model.bert.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3357 [00:01<1:15:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[ 0.0588,  0.1269],\n",
      "        [-0.0430,  0.0238],\n",
      "        [ 0.0125,  0.0627],\n",
      "        [-0.0555, -0.0253],\n",
      "        [-0.0214,  0.0545],\n",
      "        [-0.0230,  0.0212],\n",
      "        [-0.0391,  0.0190],\n",
      "        [ 0.0672,  0.1003],\n",
      "        [-0.0649,  0.0556],\n",
      "        [ 0.0323,  0.0609],\n",
      "        [-0.0181,  0.0080],\n",
      "        [-0.1015,  0.0166],\n",
      "        [-0.0379,  0.0476],\n",
      "        [-0.0026,  0.0589],\n",
      "        [-0.0239,  0.0940],\n",
      "        [ 0.0249,  0.0958],\n",
      "        [-0.0481,  0.1130],\n",
      "        [-0.0283,  0.0137],\n",
      "        [-0.0786,  0.0753],\n",
      "        [-0.0740,  0.0525],\n",
      "        [-0.0161,  0.0340],\n",
      "        [-0.0591, -0.0367],\n",
      "        [-0.0344,  0.0474],\n",
      "        [-0.0605,  0.0406],\n",
      "        [ 0.0501,  0.0676],\n",
      "        [-0.0312,  0.1087],\n",
      "        [-0.0285,  0.0611],\n",
      "        [ 0.0212,  0.0591],\n",
      "        [-0.0053,  0.0694],\n",
      "        [-0.0466,  0.0372],\n",
      "        [ 0.0224,  0.0464],\n",
      "        [-0.0156,  0.0402]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.0963, 0.0000],\n",
      "        [0.6320, 1.0000],\n",
      "        [0.1213, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4669, 1.0000],\n",
      "        [0.6182, 1.0000],\n",
      "        [0.6821, 1.0000],\n",
      "        [0.1723, 0.0000],\n",
      "        [0.5979, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.8985, 1.0000],\n",
      "        [0.4486, 1.0000],\n",
      "        [0.7529, 1.0000],\n",
      "        [0.6500, 1.0000],\n",
      "        [0.9374, 1.0000],\n",
      "        [0.1628, 0.0000],\n",
      "        [0.5550, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4596, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2144, 0.0000],\n",
      "        [0.0598, 0.0000],\n",
      "        [0.8293, 1.0000],\n",
      "        [0.6094, 1.0000],\n",
      "        [0.5483, 1.0000],\n",
      "        [0.2340, 0.0000],\n",
      "        [0.4492, 1.0000],\n",
      "        [0.4863, 1.0000],\n",
      "        [0.5577, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3513, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-1.0371e+00, -9.4021e-02],\n",
      "        [-1.0522e+00, -4.2180e-02],\n",
      "        [-1.0180e+00,  8.8199e-02],\n",
      "        [-1.1123e+00, -5.3850e-04],\n",
      "        [-1.0776e+00,  2.0855e-03],\n",
      "        [-1.0511e+00, -1.1433e-02],\n",
      "        [-1.0731e+00, -2.7699e-02],\n",
      "        [-1.1149e+00,  1.5549e-02],\n",
      "        [-1.0809e+00, -6.9718e-03],\n",
      "        [-1.0831e+00, -1.9993e-02],\n",
      "        [-1.1313e+00, -1.3963e-02],\n",
      "        [-1.0369e+00,  1.4211e-02],\n",
      "        [-9.9171e-01, -9.1817e-03],\n",
      "        [-8.9451e-01,  4.5508e-05],\n",
      "        [-1.0978e+00, -3.8842e-02],\n",
      "        [-1.0020e+00,  7.6807e-02],\n",
      "        [-1.1288e+00,  7.9164e-02],\n",
      "        [-1.1457e+00,  2.6607e-02],\n",
      "        [-1.0634e+00,  3.2379e-02],\n",
      "        [-7.7977e-01,  1.7017e-02],\n",
      "        [-1.0862e+00,  2.7277e-02],\n",
      "        [-1.0378e+00,  7.8115e-03],\n",
      "        [-9.5310e-01,  2.3642e-02],\n",
      "        [-1.0519e+00,  2.0890e-02],\n",
      "        [-1.0658e+00,  2.3388e-02],\n",
      "        [-1.0502e+00,  2.8841e-02],\n",
      "        [-1.0509e+00,  3.3222e-02],\n",
      "        [-9.7448e-01,  4.4470e-02],\n",
      "        [-1.1166e+00, -3.5417e-02],\n",
      "        [-8.4998e-01,  2.7275e-02],\n",
      "        [-1.1478e+00,  1.8189e-03],\n",
      "        [-1.0342e+00, -7.1521e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.5676, 1.0000],\n",
      "        [0.6442, 1.0000],\n",
      "        [0.4039, 0.0000],\n",
      "        [0.3621, 0.0000],\n",
      "        [0.5945, 1.0000],\n",
      "        [0.6828, 1.0000],\n",
      "        [0.6433, 1.0000],\n",
      "        [0.2211, 0.0000],\n",
      "        [0.5768, 1.0000],\n",
      "        [0.3751, 0.0000],\n",
      "        [0.3322, 0.0000],\n",
      "        [0.1463, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4557, 1.0000],\n",
      "        [0.4789, 1.0000],\n",
      "        [0.2169, 0.0000],\n",
      "        [0.3883, 0.0000],\n",
      "        [0.9173, 1.0000],\n",
      "        [0.3022, 0.0000],\n",
      "        [0.2486, 0.0000],\n",
      "        [0.4839, 1.0000],\n",
      "        [0.0127, 0.0000],\n",
      "        [0.1244, 0.0000],\n",
      "        [0.2622, 0.0000],\n",
      "        [0.0913, 0.0000],\n",
      "        [0.5007, 1.0000],\n",
      "        [0.2285, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4933, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2847, 0.0000],\n",
      "        [0.9087, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3357 [00:01<23:37,  2.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.4187, -0.0563],\n",
      "        [-0.3517, -0.0536],\n",
      "        [-0.4358,  0.0562],\n",
      "        [-0.4453, -0.0342],\n",
      "        [-0.4390,  0.0189],\n",
      "        [-0.4587,  0.0096],\n",
      "        [-0.3770,  0.0599],\n",
      "        [-0.3614, -0.0674],\n",
      "        [-0.3902,  0.0226],\n",
      "        [-0.4286, -0.0233],\n",
      "        [-0.3812,  0.0387],\n",
      "        [-0.4332, -0.0460],\n",
      "        [-0.3920,  0.0068],\n",
      "        [-0.4250,  0.0015],\n",
      "        [-0.3639,  0.0086],\n",
      "        [-0.4540,  0.0170],\n",
      "        [-0.4002, -0.0060],\n",
      "        [-0.4378, -0.0541],\n",
      "        [-0.3564, -0.0517],\n",
      "        [-0.4051,  0.0347],\n",
      "        [-0.3832, -0.0201],\n",
      "        [-0.4023, -0.0399],\n",
      "        [-0.3582, -0.1124],\n",
      "        [-0.3918,  0.0275],\n",
      "        [-0.4968,  0.0053],\n",
      "        [-0.3984,  0.0348],\n",
      "        [-0.3854, -0.0844],\n",
      "        [-0.3413,  0.1116],\n",
      "        [-0.5022,  0.0478],\n",
      "        [-0.4312, -0.0183],\n",
      "        [-0.3904,  0.0016],\n",
      "        [-0.4187,  0.0274]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.6006, 1.0000],\n",
      "        [0.5418, 1.0000],\n",
      "        [0.7063, 1.0000],\n",
      "        [0.2505, 0.0000],\n",
      "        [0.2952, 0.0000],\n",
      "        [0.6060, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6331, 1.0000],\n",
      "        [0.3812, 0.0000],\n",
      "        [0.3870, 0.0000],\n",
      "        [0.8494, 1.0000],\n",
      "        [0.2066, 0.0000],\n",
      "        [0.8155, 1.0000],\n",
      "        [0.6331, 1.0000],\n",
      "        [0.7422, 1.0000],\n",
      "        [0.1500, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6590, 1.0000],\n",
      "        [0.7704, 1.0000],\n",
      "        [0.3554, 0.0000],\n",
      "        [0.6651, 1.0000],\n",
      "        [0.5158, 1.0000],\n",
      "        [0.2279, 0.0000],\n",
      "        [0.3105, 0.0000],\n",
      "        [0.5804, 1.0000],\n",
      "        [0.9139, 1.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.4912, 1.0000],\n",
      "        [0.5453, 1.0000],\n",
      "        [0.1579, 0.0000],\n",
      "        [0.0792, 0.0000],\n",
      "        [0.5566, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[ 3.9559e-01,  7.0712e-03],\n",
      "        [ 3.5692e-01, -2.4095e-02],\n",
      "        [ 4.0846e-01, -2.3139e-02],\n",
      "        [ 4.2804e-01,  3.8777e-02],\n",
      "        [ 3.9896e-01,  3.1212e-03],\n",
      "        [ 3.1732e-01,  9.3619e-03],\n",
      "        [ 4.2444e-01, -6.0030e-03],\n",
      "        [ 4.3132e-01, -4.9812e-02],\n",
      "        [ 3.7508e-01, -1.9051e-02],\n",
      "        [ 3.8617e-01, -7.4579e-02],\n",
      "        [ 3.8586e-01, -4.2963e-02],\n",
      "        [ 4.5062e-01, -5.4866e-02],\n",
      "        [ 3.8004e-01,  2.6876e-02],\n",
      "        [ 4.3590e-01, -5.9917e-02],\n",
      "        [ 4.1314e-01, -2.1816e-02],\n",
      "        [ 3.8685e-01,  1.0302e-02],\n",
      "        [ 3.9350e-01, -4.3102e-02],\n",
      "        [ 3.7725e-01, -4.7290e-02],\n",
      "        [ 3.9911e-01, -7.1723e-02],\n",
      "        [ 3.5292e-01,  1.1918e-02],\n",
      "        [ 3.7614e-01, -7.5155e-02],\n",
      "        [ 3.8618e-01, -2.9540e-02],\n",
      "        [ 4.3378e-01, -6.6081e-02],\n",
      "        [ 3.3316e-01, -4.8911e-02],\n",
      "        [ 3.8323e-01, -4.2508e-02],\n",
      "        [ 3.5276e-01, -7.0438e-02],\n",
      "        [ 3.7834e-01, -2.1886e-04],\n",
      "        [ 3.6307e-01,  2.1699e-02],\n",
      "        [ 4.1811e-01, -2.6617e-03],\n",
      "        [ 3.8761e-01, -1.5191e-02],\n",
      "        [ 4.0905e-01, -7.6017e-02],\n",
      "        [ 3.7197e-01, -2.9059e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2871, 0.0000],\n",
      "        [0.3983, 0.0000],\n",
      "        [0.4071, 0.0000],\n",
      "        [0.3667, 0.0000],\n",
      "        [0.1289, 0.0000],\n",
      "        [0.3093, 0.0000],\n",
      "        [0.2144, 0.0000],\n",
      "        [0.5153, 1.0000],\n",
      "        [0.5791, 1.0000],\n",
      "        [0.3721, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6835, 1.0000],\n",
      "        [0.3604, 0.0000],\n",
      "        [0.2223, 0.0000],\n",
      "        [0.3893, 0.0000],\n",
      "        [0.4206, 0.0000],\n",
      "        [0.1370, 0.0000],\n",
      "        [0.8852, 1.0000],\n",
      "        [0.4575, 1.0000],\n",
      "        [0.4298, 1.0000],\n",
      "        [0.9359, 1.0000],\n",
      "        [0.5716, 1.0000],\n",
      "        [0.4014, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0955, 0.0000],\n",
      "        [0.4735, 1.0000],\n",
      "        [0.5092, 1.0000],\n",
      "        [0.3807, 0.0000],\n",
      "        [0.0586, 0.0000],\n",
      "        [0.8321, 1.0000],\n",
      "        [0.1120, 0.0000],\n",
      "        [0.2400, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/3357 [00:01<14:30,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-3.8889e-02, -1.4706e-02],\n",
      "        [ 2.8045e-02,  1.4174e-02],\n",
      "        [-8.6108e-02, -5.1298e-02],\n",
      "        [-5.9458e-02,  3.2985e-02],\n",
      "        [-2.4002e-02, -4.0897e-02],\n",
      "        [-8.6860e-02, -5.2145e-02],\n",
      "        [-3.6313e-02, -2.4368e-03],\n",
      "        [-9.4772e-02,  6.3473e-03],\n",
      "        [-9.0269e-02,  2.2329e-02],\n",
      "        [-1.1797e-01,  4.1688e-02],\n",
      "        [-2.5231e-02,  1.3328e-02],\n",
      "        [-1.0014e-01,  2.1012e-02],\n",
      "        [ 3.5751e-02, -3.2599e-02],\n",
      "        [-9.8101e-02,  3.8974e-02],\n",
      "        [-5.3977e-02,  4.6447e-03],\n",
      "        [-4.8119e-02, -5.4272e-02],\n",
      "        [-5.2124e-02, -4.2461e-02],\n",
      "        [-2.3007e-02, -5.2179e-02],\n",
      "        [-2.5745e-02, -5.4895e-02],\n",
      "        [-9.0170e-02, -1.5029e-02],\n",
      "        [-4.2528e-02,  5.7858e-02],\n",
      "        [-1.2221e-01, -7.4119e-03],\n",
      "        [-5.1919e-02, -3.4303e-02],\n",
      "        [-8.4867e-02,  2.2764e-02],\n",
      "        [-6.2674e-02, -1.3755e-05],\n",
      "        [-5.0001e-02,  3.8489e-02],\n",
      "        [ 3.3043e-03,  9.9998e-03],\n",
      "        [-4.9087e-02, -2.8990e-02],\n",
      "        [-7.2910e-02, -4.3354e-02],\n",
      "        [-2.8201e-02, -1.5118e-02],\n",
      "        [-6.0297e-02,  1.2813e-02],\n",
      "        [-9.4754e-02,  1.8054e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.8356, 1.0000],\n",
      "        [0.0556, 0.0000],\n",
      "        [0.5480, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3739, 0.0000],\n",
      "        [0.5446, 1.0000],\n",
      "        [0.4864, 1.0000],\n",
      "        [0.3120, 0.0000],\n",
      "        [0.4666, 1.0000],\n",
      "        [0.2528, 0.0000],\n",
      "        [0.2197, 0.0000],\n",
      "        [0.1846, 0.0000],\n",
      "        [0.2597, 0.0000],\n",
      "        [0.5591, 1.0000],\n",
      "        [0.4225, 0.0000],\n",
      "        [0.3442, 0.0000],\n",
      "        [0.2725, 0.0000],\n",
      "        [0.3290, 0.0000],\n",
      "        [0.3143, 0.0000],\n",
      "        [0.3303, 0.0000],\n",
      "        [0.7941, 1.0000],\n",
      "        [0.4580, 1.0000],\n",
      "        [0.6546, 1.0000],\n",
      "        [0.3277, 0.0000],\n",
      "        [0.0851, 0.0000],\n",
      "        [0.8044, 1.0000],\n",
      "        [0.5842, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2759, 0.0000],\n",
      "        [0.8807, 1.0000],\n",
      "        [0.8078, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-5.4071e-01, -3.4603e-02],\n",
      "        [-5.4274e-01, -1.3125e-03],\n",
      "        [-5.4080e-01, -3.8437e-02],\n",
      "        [-4.6565e-01, -2.5808e-02],\n",
      "        [-5.2107e-01, -2.0172e-03],\n",
      "        [-4.6868e-01, -4.2311e-02],\n",
      "        [-4.5633e-01, -4.0891e-02],\n",
      "        [-5.2982e-01, -2.8740e-02],\n",
      "        [-4.7832e-01, -3.3426e-02],\n",
      "        [-4.8818e-01, -3.6068e-02],\n",
      "        [-4.4032e-01, -3.6895e-02],\n",
      "        [-4.7391e-01, -3.3403e-02],\n",
      "        [-5.2677e-01,  5.1474e-03],\n",
      "        [-5.1882e-01, -4.3527e-02],\n",
      "        [-5.0676e-01, -5.3312e-04],\n",
      "        [-4.2733e-01, -2.4534e-02],\n",
      "        [-5.2578e-01, -2.2199e-02],\n",
      "        [-5.4454e-01, -2.6805e-02],\n",
      "        [-4.3465e-01, -3.7374e-02],\n",
      "        [-5.0454e-01, -5.7862e-02],\n",
      "        [-5.2010e-01,  2.1208e-02],\n",
      "        [-4.4162e-01,  2.1522e-02],\n",
      "        [-5.1783e-01, -5.4328e-02],\n",
      "        [-5.3792e-01, -3.0207e-02],\n",
      "        [-4.7877e-01, -7.0544e-02],\n",
      "        [-5.2237e-01, -1.8102e-02],\n",
      "        [-5.0371e-01, -2.6834e-02],\n",
      "        [-4.9228e-01, -2.9871e-02],\n",
      "        [-4.2014e-01,  1.5423e-02],\n",
      "        [-4.7970e-01, -3.5911e-02],\n",
      "        [-4.9140e-01,  7.3769e-03],\n",
      "        [-4.9703e-01, -4.2587e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.0000, 0.0000],\n",
      "        [0.6349, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5858, 1.0000],\n",
      "        [0.2174, 0.0000],\n",
      "        [0.1352, 0.0000],\n",
      "        [0.4200, 0.0000],\n",
      "        [0.7766, 1.0000],\n",
      "        [0.4526, 1.0000],\n",
      "        [0.8055, 1.0000],\n",
      "        [0.5607, 1.0000],\n",
      "        [0.1842, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6174, 1.0000],\n",
      "        [0.4481, 1.0000],\n",
      "        [0.5491, 1.0000],\n",
      "        [0.2276, 0.0000],\n",
      "        [0.5013, 1.0000],\n",
      "        [0.0339, 0.0000],\n",
      "        [0.7519, 1.0000],\n",
      "        [0.4924, 1.0000],\n",
      "        [0.1888, 0.0000],\n",
      "        [0.6482, 1.0000],\n",
      "        [0.1997, 0.0000],\n",
      "        [0.3906, 0.0000],\n",
      "        [0.8308, 1.0000],\n",
      "        [0.5461, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7769, 1.0000],\n",
      "        [0.4554, 1.0000],\n",
      "        [0.6607, 1.0000],\n",
      "        [0.5796, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/3357 [00:02<11:18,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.2938, -0.0717],\n",
      "        [-0.2486, -0.0220],\n",
      "        [-0.3792, -0.0207],\n",
      "        [-0.4460,  0.0183],\n",
      "        [-0.2087,  0.0983],\n",
      "        [-0.2624, -0.0107],\n",
      "        [-0.2769,  0.0037],\n",
      "        [-0.2766,  0.0049],\n",
      "        [-0.4019, -0.0195],\n",
      "        [-0.2930, -0.0293],\n",
      "        [-0.2606,  0.0193],\n",
      "        [-0.3659,  0.0007],\n",
      "        [-0.2377,  0.0123],\n",
      "        [-0.2963, -0.0325],\n",
      "        [-0.3441,  0.0605],\n",
      "        [-0.2476,  0.0078],\n",
      "        [-0.2759, -0.0333],\n",
      "        [-0.4062, -0.0505],\n",
      "        [-0.3508, -0.0416],\n",
      "        [-0.3600, -0.0407],\n",
      "        [-0.2271, -0.0190],\n",
      "        [-0.2896, -0.0304],\n",
      "        [-0.2295,  0.0378],\n",
      "        [-0.4200,  0.0077],\n",
      "        [-0.2950, -0.0073],\n",
      "        [-0.3816, -0.0169],\n",
      "        [-0.3012, -0.0400],\n",
      "        [-0.3400, -0.0373],\n",
      "        [-0.3654, -0.0275],\n",
      "        [-0.2260, -0.0830],\n",
      "        [-0.2603,  0.0265],\n",
      "        [-0.4231, -0.0011]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2231, 0.0000],\n",
      "        [0.2292, 0.0000],\n",
      "        [0.5748, 1.0000],\n",
      "        [0.2619, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2185, 0.0000],\n",
      "        [0.4170, 0.0000],\n",
      "        [0.3889, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2334, 0.0000],\n",
      "        [0.1904, 0.0000],\n",
      "        [0.2033, 0.0000],\n",
      "        [0.6923, 1.0000],\n",
      "        [0.7757, 1.0000],\n",
      "        [0.0684, 0.0000],\n",
      "        [0.7950, 1.0000],\n",
      "        [0.3532, 0.0000],\n",
      "        [0.0288, 0.0000],\n",
      "        [0.3214, 0.0000],\n",
      "        [0.0565, 0.0000],\n",
      "        [0.3731, 0.0000],\n",
      "        [0.2175, 0.0000],\n",
      "        [0.2657, 0.0000],\n",
      "        [0.0381, 0.0000],\n",
      "        [0.3577, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1834, 0.0000],\n",
      "        [0.1235, 0.0000],\n",
      "        [0.2229, 0.0000],\n",
      "        [0.6096, 1.0000],\n",
      "        [0.2023, 0.0000],\n",
      "        [0.1373, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-0.7661, -0.0738],\n",
      "        [-0.8997, -0.0474],\n",
      "        [-0.9135, -0.0354],\n",
      "        [-0.8996, -0.0065],\n",
      "        [-0.7982, -0.0170],\n",
      "        [-0.8574,  0.0160],\n",
      "        [-0.8955, -0.0621],\n",
      "        [-0.8499, -0.0320],\n",
      "        [-0.8404, -0.0337],\n",
      "        [-0.7414, -0.0904],\n",
      "        [-0.7330, -0.0376],\n",
      "        [-1.0031, -0.0299],\n",
      "        [-0.8103, -0.0512],\n",
      "        [-0.9003,  0.0036],\n",
      "        [-0.8816, -0.0057],\n",
      "        [-0.9236, -0.0485],\n",
      "        [-0.9069,  0.0072],\n",
      "        [-0.8405, -0.0223],\n",
      "        [-0.8787, -0.0659],\n",
      "        [-0.7658,  0.0552],\n",
      "        [-0.8243, -0.0506],\n",
      "        [-0.8970, -0.0462],\n",
      "        [-0.8793, -0.0073],\n",
      "        [-0.8837, -0.0542],\n",
      "        [-0.8744, -0.0152],\n",
      "        [-0.9231, -0.0318],\n",
      "        [-0.8617, -0.0866],\n",
      "        [-0.9091, -0.0358],\n",
      "        [-0.7245, -0.0345],\n",
      "        [-0.9131, -0.0451],\n",
      "        [-0.7480, -0.0070],\n",
      "        [-0.7108, -0.0784]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.4550, 1.0000],\n",
      "        [0.6100, 1.0000],\n",
      "        [0.0847, 0.0000],\n",
      "        [0.3713, 0.0000],\n",
      "        [0.1066, 0.0000],\n",
      "        [0.1456, 0.0000],\n",
      "        [0.4986, 1.0000],\n",
      "        [0.2600, 0.0000],\n",
      "        [0.5772, 1.0000],\n",
      "        [0.3823, 0.0000],\n",
      "        [0.5444, 1.0000],\n",
      "        [0.4628, 1.0000],\n",
      "        [0.9342, 1.0000],\n",
      "        [0.5690, 1.0000],\n",
      "        [0.6074, 1.0000],\n",
      "        [0.2579, 0.0000],\n",
      "        [0.1902, 0.0000],\n",
      "        [0.4500, 1.0000],\n",
      "        [0.9878, 1.0000],\n",
      "        [0.5736, 1.0000],\n",
      "        [0.6893, 1.0000],\n",
      "        [0.7357, 1.0000],\n",
      "        [0.7980, 1.0000],\n",
      "        [0.7890, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3993, 0.0000],\n",
      "        [0.1610, 0.0000],\n",
      "        [0.3554, 0.0000],\n",
      "        [0.8376, 1.0000],\n",
      "        [0.6546, 1.0000],\n",
      "        [0.4357, 1.0000],\n",
      "        [0.7816, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/3357 [00:02<09:54,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.4867,  0.0078],\n",
      "        [-0.6377, -0.0145],\n",
      "        [-0.3858, -0.0546],\n",
      "        [-0.3217, -0.0378],\n",
      "        [-0.5668,  0.0406],\n",
      "        [-0.4049, -0.0449],\n",
      "        [-0.3814, -0.0335],\n",
      "        [-0.3673, -0.0274],\n",
      "        [-0.4807, -0.0097],\n",
      "        [-0.3254, -0.0508],\n",
      "        [-0.3519, -0.0198],\n",
      "        [-0.3620, -0.0485],\n",
      "        [-0.3494, -0.0274],\n",
      "        [-0.3930, -0.0255],\n",
      "        [-0.2869, -0.0702],\n",
      "        [-0.2910, -0.0509],\n",
      "        [-0.4215, -0.0441],\n",
      "        [-0.3635, -0.0268],\n",
      "        [-0.4292, -0.0406],\n",
      "        [-0.4176, -0.0737],\n",
      "        [-0.2926, -0.0491],\n",
      "        [-0.3950, -0.0230],\n",
      "        [-0.3382, -0.0505],\n",
      "        [-0.3593, -0.0151],\n",
      "        [-0.4135,  0.0067],\n",
      "        [-0.3390, -0.0742],\n",
      "        [-0.5062, -0.0292],\n",
      "        [-0.3143,  0.0295],\n",
      "        [-0.4555, -0.0007],\n",
      "        [-0.3011, -0.0221],\n",
      "        [-0.3906,  0.0218],\n",
      "        [-0.3405,  0.0060]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.3992, 0.0000],\n",
      "        [0.4501, 1.0000],\n",
      "        [0.0254, 0.0000],\n",
      "        [0.6603, 1.0000],\n",
      "        [0.5403, 1.0000],\n",
      "        [0.6280, 1.0000],\n",
      "        [0.8344, 1.0000],\n",
      "        [0.5146, 1.0000],\n",
      "        [0.4698, 1.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5146, 1.0000],\n",
      "        [0.2419, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1729, 0.0000],\n",
      "        [0.8216, 1.0000],\n",
      "        [0.3941, 0.0000],\n",
      "        [0.8114, 1.0000],\n",
      "        [0.1331, 0.0000],\n",
      "        [0.2326, 0.0000],\n",
      "        [0.6940, 1.0000],\n",
      "        [0.6107, 1.0000],\n",
      "        [0.1530, 0.0000],\n",
      "        [0.2760, 0.0000],\n",
      "        [0.3117, 0.0000],\n",
      "        [0.1741, 0.0000],\n",
      "        [0.3885, 0.0000],\n",
      "        [0.1257, 0.0000],\n",
      "        [0.5207, 1.0000],\n",
      "        [0.3482, 0.0000],\n",
      "        [0.7102, 1.0000],\n",
      "        [0.6249, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-0.4112, -0.0213],\n",
      "        [-0.1950, -0.0383],\n",
      "        [-0.1577, -0.0308],\n",
      "        [-0.1400, -0.0481],\n",
      "        [-0.1836, -0.0283],\n",
      "        [-0.4219,  0.0339],\n",
      "        [-0.2528, -0.0075],\n",
      "        [-0.1485, -0.0236],\n",
      "        [-0.1656,  0.0061],\n",
      "        [-0.1798,  0.0019],\n",
      "        [-0.2269,  0.0152],\n",
      "        [-0.1728, -0.0355],\n",
      "        [-0.1810, -0.0317],\n",
      "        [-0.1504, -0.0280],\n",
      "        [-0.1476,  0.0226],\n",
      "        [-0.1458, -0.0276],\n",
      "        [-0.1215, -0.0790],\n",
      "        [-0.2050,  0.0069],\n",
      "        [-0.1665, -0.0301],\n",
      "        [-0.2253, -0.0453],\n",
      "        [-0.3607,  0.0151],\n",
      "        [-0.1749, -0.0520],\n",
      "        [-0.2917, -0.0076],\n",
      "        [-0.2100, -0.0396],\n",
      "        [-0.1955,  0.0234],\n",
      "        [-0.1995, -0.0086],\n",
      "        [-0.1483, -0.0031],\n",
      "        [-0.2610, -0.0088],\n",
      "        [-0.1617, -0.0187],\n",
      "        [-0.1309, -0.0284],\n",
      "        [-0.1830,  0.0174],\n",
      "        [-0.2431, -0.0233]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.0000, 0.0000],\n",
      "        [0.4406, 1.0000],\n",
      "        [0.5237, 1.0000],\n",
      "        [0.8110, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0847, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2182, 0.0000],\n",
      "        [0.6142, 1.0000],\n",
      "        [0.3348, 0.0000],\n",
      "        [0.1799, 0.0000],\n",
      "        [0.4559, 1.0000],\n",
      "        [0.3993, 0.0000],\n",
      "        [0.7858, 1.0000],\n",
      "        [0.4330, 1.0000],\n",
      "        [0.4897, 1.0000],\n",
      "        [0.4593, 1.0000],\n",
      "        [0.7318, 1.0000],\n",
      "        [0.5062, 1.0000],\n",
      "        [0.5998, 1.0000],\n",
      "        [0.1679, 0.0000],\n",
      "        [0.8391, 1.0000],\n",
      "        [0.5394, 1.0000],\n",
      "        [0.1349, 0.0000],\n",
      "        [0.2686, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3728, 0.0000],\n",
      "        [0.4543, 1.0000],\n",
      "        [0.5078, 1.0000],\n",
      "        [0.0854, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1825, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/3357 [00:02<09:18,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.5421,  0.0108],\n",
      "        [-0.6039,  0.0067],\n",
      "        [-0.3602, -0.0117],\n",
      "        [-0.4661, -0.0477],\n",
      "        [-0.3756, -0.0057],\n",
      "        [-0.3518,  0.0110],\n",
      "        [-0.3227, -0.0286],\n",
      "        [-0.4402,  0.0181],\n",
      "        [-0.4404, -0.0308],\n",
      "        [-0.4626,  0.0292],\n",
      "        [-0.3489, -0.0017],\n",
      "        [-0.3659,  0.0394],\n",
      "        [-0.3779, -0.0076],\n",
      "        [-0.3661,  0.0289],\n",
      "        [-0.4673, -0.0014],\n",
      "        [-0.3822,  0.0330],\n",
      "        [-0.4381,  0.0097],\n",
      "        [-0.3869, -0.0155],\n",
      "        [-0.3715, -0.0017],\n",
      "        [-0.4619,  0.0080],\n",
      "        [-0.3663, -0.0240],\n",
      "        [-0.4684,  0.0107],\n",
      "        [-0.5199, -0.0059],\n",
      "        [-0.4185,  0.0035],\n",
      "        [-0.3520,  0.0199],\n",
      "        [-0.4734, -0.0096],\n",
      "        [-0.3551, -0.0402],\n",
      "        [-0.4508,  0.0242],\n",
      "        [-0.4489, -0.0160],\n",
      "        [-0.5034, -0.0015],\n",
      "        [-0.4131,  0.0432],\n",
      "        [-0.4096,  0.0426]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2909, 0.0000],\n",
      "        [0.0797, 0.0000],\n",
      "        [0.8448, 1.0000],\n",
      "        [0.0677, 0.0000],\n",
      "        [0.5862, 1.0000],\n",
      "        [0.3541, 0.0000],\n",
      "        [0.6603, 1.0000],\n",
      "        [0.7687, 1.0000],\n",
      "        [0.6056, 1.0000],\n",
      "        [0.2466, 0.0000],\n",
      "        [0.5725, 1.0000],\n",
      "        [0.3555, 0.0000],\n",
      "        [0.7706, 1.0000],\n",
      "        [0.2851, 0.0000],\n",
      "        [0.1270, 0.0000],\n",
      "        [0.5539, 1.0000],\n",
      "        [0.6856, 1.0000],\n",
      "        [0.2683, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2252, 0.0000],\n",
      "        [0.9409, 1.0000],\n",
      "        [0.2649, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6468, 1.0000],\n",
      "        [0.9444, 1.0000],\n",
      "        [0.5260, 1.0000],\n",
      "        [0.7890, 1.0000],\n",
      "        [0.3322, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5967, 1.0000],\n",
      "        [0.3379, 0.0000],\n",
      "        [0.5699, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-5.0366e-01,  1.4688e-02],\n",
      "        [-2.0823e-01, -3.6127e-02],\n",
      "        [-2.1297e-01,  7.4900e-04],\n",
      "        [-1.3916e-01,  1.3549e-03],\n",
      "        [-2.0621e-01, -1.7122e-02],\n",
      "        [-1.3698e-01, -1.0759e-02],\n",
      "        [-5.9068e-01,  1.5834e-02],\n",
      "        [-2.0806e-01, -2.7087e-02],\n",
      "        [-2.5379e-01, -1.0405e-02],\n",
      "        [-2.5041e-01,  2.1500e-02],\n",
      "        [-1.1370e-01, -1.5190e-02],\n",
      "        [-1.8450e-01, -9.6667e-05],\n",
      "        [-1.9141e-01, -4.0860e-02],\n",
      "        [-1.3863e-01, -4.3839e-02],\n",
      "        [-2.3722e-01, -1.5867e-02],\n",
      "        [-4.9606e-01,  3.1200e-02],\n",
      "        [-5.1889e-01, -8.5441e-03],\n",
      "        [-1.1963e-01, -4.7502e-02],\n",
      "        [-2.2865e-01, -8.8188e-02],\n",
      "        [-2.9153e-01,  2.1087e-02],\n",
      "        [-1.9673e-01, -6.2258e-02],\n",
      "        [-1.7131e-01, -7.2375e-02],\n",
      "        [-2.3137e-01, -1.8381e-02],\n",
      "        [-5.9084e-01,  1.8847e-02],\n",
      "        [-3.3419e-01, -2.0706e-02],\n",
      "        [-2.8433e-01, -1.6252e-02],\n",
      "        [-1.8518e-01, -7.5512e-02],\n",
      "        [-2.7191e-01, -1.0754e-02],\n",
      "        [-2.8558e-01, -7.2666e-02],\n",
      "        [-2.1677e-01, -2.6409e-02],\n",
      "        [-2.2012e-01,  3.1855e-03],\n",
      "        [-1.8285e-01, -1.0116e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.3712, 0.0000],\n",
      "        [0.1442, 0.0000],\n",
      "        [0.6214, 1.0000],\n",
      "        [0.7431, 1.0000],\n",
      "        [0.3009, 0.0000],\n",
      "        [0.5708, 1.0000],\n",
      "        [0.0212, 0.0000],\n",
      "        [0.0976, 0.0000],\n",
      "        [0.5985, 1.0000],\n",
      "        [0.4024, 0.0000],\n",
      "        [0.2593, 0.0000],\n",
      "        [0.4852, 1.0000],\n",
      "        [0.6184, 1.0000],\n",
      "        [0.4243, 0.0000],\n",
      "        [0.4026, 0.0000],\n",
      "        [0.3216, 0.0000],\n",
      "        [0.4249, 0.0000],\n",
      "        [0.7712, 1.0000],\n",
      "        [0.3927, 0.0000],\n",
      "        [0.3047, 0.0000],\n",
      "        [0.6574, 1.0000],\n",
      "        [0.1859, 0.0000],\n",
      "        [0.3865, 0.0000],\n",
      "        [0.1219, 0.0000],\n",
      "        [0.1658, 0.0000],\n",
      "        [0.3602, 0.0000],\n",
      "        [0.9764, 1.0000],\n",
      "        [0.6271, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3095, 0.0000],\n",
      "        [0.5218, 1.0000],\n",
      "        [0.5080, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/3357 [00:03<09:01,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-3.1509e-01, -6.2346e-02],\n",
      "        [-3.9038e-01,  1.8021e-02],\n",
      "        [-2.2033e-01, -1.2423e-02],\n",
      "        [-1.8244e-01,  4.2155e-03],\n",
      "        [-7.2311e-01, -6.5744e-04],\n",
      "        [-1.9748e-01, -2.5731e-02],\n",
      "        [-5.2614e-01,  1.4807e-02],\n",
      "        [-1.7992e-01, -3.8019e-02],\n",
      "        [-4.1436e-01, -1.3084e-02],\n",
      "        [-3.6526e-01, -6.7787e-02],\n",
      "        [-3.2122e-01, -1.1954e-03],\n",
      "        [-2.2302e-01,  2.6947e-02],\n",
      "        [-6.2951e-01, -1.2892e-02],\n",
      "        [-5.3661e-01, -1.6577e-02],\n",
      "        [-2.6753e-01, -9.9108e-03],\n",
      "        [-3.3333e-01, -3.5280e-02],\n",
      "        [-4.0590e-01, -1.5158e-02],\n",
      "        [-2.6006e-01, -1.7845e-02],\n",
      "        [-7.2246e-01,  3.3911e-02],\n",
      "        [-3.2488e-01,  3.7891e-02],\n",
      "        [-4.6163e-01, -6.1541e-03],\n",
      "        [-4.5644e-01, -1.0436e-02],\n",
      "        [-3.0061e-01, -3.0839e-02],\n",
      "        [-1.8966e-01, -1.5388e-02],\n",
      "        [-6.5997e-01, -1.1157e-02],\n",
      "        [-3.2768e-01, -3.6429e-02],\n",
      "        [-4.0178e-01,  6.4642e-03],\n",
      "        [-6.4099e-01,  1.4793e-02],\n",
      "        [-7.0155e-01,  2.6542e-02],\n",
      "        [-6.5982e-01, -7.4259e-03],\n",
      "        [-1.9143e-01, -7.7543e-03],\n",
      "        [-5.9075e-01,  1.4997e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2414, 0.0000],\n",
      "        [0.2193, 0.0000],\n",
      "        [0.6119, 1.0000],\n",
      "        [0.1965, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.8439, 1.0000],\n",
      "        [0.5210, 1.0000],\n",
      "        [0.7087, 1.0000],\n",
      "        [0.1888, 0.0000],\n",
      "        [0.0346, 0.0000],\n",
      "        [0.5197, 1.0000],\n",
      "        [0.3571, 0.0000],\n",
      "        [0.4940, 1.0000],\n",
      "        [0.6730, 1.0000],\n",
      "        [0.0896, 0.0000],\n",
      "        [0.2840, 0.0000],\n",
      "        [0.4493, 1.0000],\n",
      "        [0.8020, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1943, 0.0000],\n",
      "        [0.0279, 0.0000],\n",
      "        [0.2007, 0.0000],\n",
      "        [0.4555, 1.0000],\n",
      "        [0.4877, 1.0000],\n",
      "        [0.4903, 1.0000],\n",
      "        [0.7955, 1.0000],\n",
      "        [0.4106, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4294, 1.0000],\n",
      "        [0.4451, 1.0000],\n",
      "        [0.1553, 0.0000],\n",
      "        [0.3494, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-4.5975e-01, -1.1756e-02],\n",
      "        [-5.1562e-01, -1.8713e-02],\n",
      "        [-4.2492e-01, -1.6365e-03],\n",
      "        [-5.9752e-01,  1.5350e-02],\n",
      "        [-5.3051e-01,  1.3378e-02],\n",
      "        [-5.7637e-01, -6.1488e-03],\n",
      "        [-4.7743e-01,  4.6418e-02],\n",
      "        [-8.1217e-01, -3.3613e-04],\n",
      "        [-4.3798e-01,  9.2050e-03],\n",
      "        [-7.2346e-01,  3.4474e-02],\n",
      "        [-7.2762e-01,  4.5062e-02],\n",
      "        [-4.5218e-01, -2.0889e-02],\n",
      "        [-7.8979e-01, -4.6784e-02],\n",
      "        [-5.8908e-01,  3.1505e-02],\n",
      "        [-3.0014e-01, -2.4513e-02],\n",
      "        [-7.2095e-01, -1.6920e-02],\n",
      "        [-6.9219e-01,  3.4570e-02],\n",
      "        [-5.3577e-01, -5.4212e-02],\n",
      "        [-2.7309e-01, -2.9267e-02],\n",
      "        [-6.8963e-01, -1.0898e-03],\n",
      "        [-8.5012e-01,  4.9824e-03],\n",
      "        [-8.2407e-01,  1.1651e-02],\n",
      "        [-3.6237e-01, -2.1224e-02],\n",
      "        [-8.1126e-01, -2.1209e-02],\n",
      "        [-6.6304e-01,  3.9706e-02],\n",
      "        [-6.2609e-01,  3.2709e-02],\n",
      "        [-5.3464e-01,  1.9074e-02],\n",
      "        [-3.4362e-01, -1.1726e-02],\n",
      "        [-5.7792e-01,  3.9952e-03],\n",
      "        [-6.2074e-01, -8.4699e-03],\n",
      "        [-6.1420e-01,  2.6540e-03],\n",
      "        [-4.5768e-01,  3.2176e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[1.0000, 1.0000],\n",
      "        [0.2117, 0.0000],\n",
      "        [0.4502, 1.0000],\n",
      "        [0.6733, 1.0000],\n",
      "        [0.4853, 1.0000],\n",
      "        [0.3374, 0.0000],\n",
      "        [0.8284, 1.0000],\n",
      "        [0.6775, 1.0000],\n",
      "        [0.5522, 1.0000],\n",
      "        [0.2383, 0.0000],\n",
      "        [0.0351, 0.0000],\n",
      "        [0.4182, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6305, 1.0000],\n",
      "        [0.2759, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5568, 1.0000],\n",
      "        [0.8428, 1.0000],\n",
      "        [0.6162, 1.0000],\n",
      "        [0.3408, 0.0000],\n",
      "        [0.5161, 1.0000],\n",
      "        [0.3804, 0.0000],\n",
      "        [0.4110, 0.0000],\n",
      "        [0.0792, 0.0000],\n",
      "        [0.4112, 0.0000],\n",
      "        [0.9122, 1.0000],\n",
      "        [0.4726, 1.0000],\n",
      "        [0.3806, 0.0000],\n",
      "        [0.0577, 0.0000],\n",
      "        [0.5365, 1.0000],\n",
      "        [0.6950, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/3357 [00:03<08:51,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[ 0.0062, -0.0215],\n",
      "        [-0.6683,  0.0135],\n",
      "        [-0.0108, -0.0162],\n",
      "        [-0.3321,  0.0172],\n",
      "        [-0.6703,  0.0187],\n",
      "        [-0.0874, -0.0438],\n",
      "        [-0.6485,  0.0297],\n",
      "        [-0.0558, -0.0064],\n",
      "        [ 0.0308, -0.0810],\n",
      "        [ 0.0329, -0.0072],\n",
      "        [-0.0116, -0.0051],\n",
      "        [-0.0270,  0.0018],\n",
      "        [ 0.0543, -0.0606],\n",
      "        [-0.6953,  0.0240],\n",
      "        [ 0.0632, -0.0461],\n",
      "        [ 0.0550, -0.0670],\n",
      "        [ 0.0050, -0.0174],\n",
      "        [-0.0559, -0.0451],\n",
      "        [ 0.0341, -0.0614],\n",
      "        [ 0.0373, -0.0310],\n",
      "        [-0.5307,  0.0512],\n",
      "        [-0.0227,  0.0079],\n",
      "        [ 0.0432, -0.0700],\n",
      "        [-0.2824,  0.0282],\n",
      "        [-0.1139, -0.0353],\n",
      "        [-0.0832, -0.0317],\n",
      "        [-0.0867, -0.0270],\n",
      "        [-0.5896, -0.0010],\n",
      "        [-0.7150,  0.0066],\n",
      "        [-0.1537, -0.0371],\n",
      "        [ 0.0315, -0.0257],\n",
      "        [-0.1343, -0.0439]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.0000, 0.0000],\n",
      "        [0.3666, 0.0000],\n",
      "        [0.6372, 1.0000],\n",
      "        [0.4850, 1.0000],\n",
      "        [0.2251, 0.0000],\n",
      "        [0.3434, 0.0000],\n",
      "        [0.0400, 0.0000],\n",
      "        [0.0501, 0.0000],\n",
      "        [0.2265, 0.0000],\n",
      "        [0.4994, 1.0000],\n",
      "        [0.6060, 1.0000],\n",
      "        [0.6493, 1.0000],\n",
      "        [0.4539, 1.0000],\n",
      "        [0.1910, 0.0000],\n",
      "        [0.6050, 1.0000],\n",
      "        [0.9115, 1.0000],\n",
      "        [0.2267, 0.0000],\n",
      "        [0.1352, 0.0000],\n",
      "        [0.5122, 1.0000],\n",
      "        [0.6741, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1883, 0.0000],\n",
      "        [0.6813, 1.0000],\n",
      "        [0.0831, 0.0000],\n",
      "        [0.4057, 0.0000],\n",
      "        [0.5809, 1.0000],\n",
      "        [0.3986, 0.0000],\n",
      "        [0.1338, 0.0000],\n",
      "        [0.5303, 1.0000],\n",
      "        [0.4603, 1.0000],\n",
      "        [0.3942, 0.0000],\n",
      "        [0.2480, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-0.1458, -0.0491],\n",
      "        [-0.1493,  0.0118],\n",
      "        [-0.9009,  0.0484],\n",
      "        [-0.1342, -0.0073],\n",
      "        [-0.6786,  0.0108],\n",
      "        [-0.4899, -0.0125],\n",
      "        [-0.7694,  0.0162],\n",
      "        [-0.8687,  0.0196],\n",
      "        [-0.1072, -0.0503],\n",
      "        [-0.8217, -0.0086],\n",
      "        [-0.1830, -0.0307],\n",
      "        [-0.8073,  0.0519],\n",
      "        [-0.2018,  0.0264],\n",
      "        [-0.7291,  0.0029],\n",
      "        [-0.3480,  0.0257],\n",
      "        [-0.1419, -0.0195],\n",
      "        [-0.6070, -0.0135],\n",
      "        [-0.1253, -0.0596],\n",
      "        [-0.1191, -0.0173],\n",
      "        [-0.1058, -0.0203],\n",
      "        [-0.8962,  0.0265],\n",
      "        [-0.3893,  0.0509],\n",
      "        [-0.3527, -0.0103],\n",
      "        [-0.1969, -0.0229],\n",
      "        [-0.2004,  0.0039],\n",
      "        [-0.1967,  0.0113],\n",
      "        [-0.3028, -0.0314],\n",
      "        [-0.1310, -0.0444],\n",
      "        [-0.8251,  0.0297],\n",
      "        [-0.1853,  0.0159],\n",
      "        [-0.1683, -0.0127],\n",
      "        [-0.9408, -0.0152]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.1371, 0.0000],\n",
      "        [0.5825, 1.0000],\n",
      "        [0.3744, 0.0000],\n",
      "        [0.7839, 1.0000],\n",
      "        [0.6833, 1.0000],\n",
      "        [0.4190, 0.0000],\n",
      "        [0.5282, 1.0000],\n",
      "        [0.2743, 0.0000],\n",
      "        [0.5443, 1.0000],\n",
      "        [0.1723, 0.0000],\n",
      "        [0.1891, 0.0000],\n",
      "        [0.1847, 0.0000],\n",
      "        [0.4046, 0.0000],\n",
      "        [0.4449, 1.0000],\n",
      "        [0.0435, 0.0000],\n",
      "        [0.6047, 1.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.8723, 1.0000],\n",
      "        [0.6387, 1.0000],\n",
      "        [0.6520, 1.0000],\n",
      "        [0.3606, 0.0000],\n",
      "        [0.1841, 0.0000],\n",
      "        [0.2817, 0.0000],\n",
      "        [0.4949, 1.0000],\n",
      "        [0.3246, 0.0000],\n",
      "        [0.0914, 0.0000],\n",
      "        [0.8209, 1.0000],\n",
      "        [0.5790, 1.0000],\n",
      "        [0.2450, 0.0000],\n",
      "        [0.3649, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2182, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/3357 [00:03<08:46,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.4014, -0.0134],\n",
      "        [-0.1451, -0.0286],\n",
      "        [-0.3008, -0.0119],\n",
      "        [-0.1119, -0.0386],\n",
      "        [-0.1237, -0.0371],\n",
      "        [-0.1702, -0.0230],\n",
      "        [-0.4593, -0.0509],\n",
      "        [-0.7427,  0.0120],\n",
      "        [-0.1175, -0.0363],\n",
      "        [-0.3231,  0.0244],\n",
      "        [-0.1418,  0.0132],\n",
      "        [-0.1700, -0.0255],\n",
      "        [-0.1342, -0.0327],\n",
      "        [-0.1216, -0.0292],\n",
      "        [-0.1347, -0.0195],\n",
      "        [-0.1780, -0.0245],\n",
      "        [-0.6880,  0.0524],\n",
      "        [-0.1645,  0.0226],\n",
      "        [-0.1494, -0.0245],\n",
      "        [-0.3843, -0.0212],\n",
      "        [-0.5266,  0.0208],\n",
      "        [-0.8875,  0.0249],\n",
      "        [-0.7697,  0.0293],\n",
      "        [-0.1840, -0.0433],\n",
      "        [-0.1736, -0.0388],\n",
      "        [-0.2803, -0.0464],\n",
      "        [-0.7979, -0.0053],\n",
      "        [-0.8481,  0.0143],\n",
      "        [-0.1137, -0.0541],\n",
      "        [-0.2145,  0.0035],\n",
      "        [-0.1452, -0.0298],\n",
      "        [-0.1462, -0.0147]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2136, 0.0000],\n",
      "        [0.8255, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1705, 0.0000],\n",
      "        [0.0915, 0.0000],\n",
      "        [0.3084, 0.0000],\n",
      "        [0.0680, 0.0000],\n",
      "        [0.3141, 0.0000],\n",
      "        [0.6052, 1.0000],\n",
      "        [0.0077, 0.0000],\n",
      "        [0.3758, 0.0000],\n",
      "        [0.8078, 1.0000],\n",
      "        [0.5658, 1.0000],\n",
      "        [0.5546, 1.0000],\n",
      "        [0.5276, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7469, 1.0000],\n",
      "        [0.3024, 0.0000],\n",
      "        [0.3898, 0.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.3724, 0.0000],\n",
      "        [0.4079, 0.0000],\n",
      "        [0.1596, 0.0000],\n",
      "        [0.9566, 1.0000],\n",
      "        [0.3815, 0.0000],\n",
      "        [0.4197, 0.0000],\n",
      "        [0.4806, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4557, 1.0000],\n",
      "        [0.3857, 0.0000],\n",
      "        [0.1532, 0.0000],\n",
      "        [0.3127, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-0.9078,  0.0097],\n",
      "        [-0.4406,  0.0499],\n",
      "        [-0.6717,  0.0264],\n",
      "        [-0.8507,  0.0069],\n",
      "        [-0.9179, -0.0042],\n",
      "        [-0.8048,  0.0391],\n",
      "        [-0.6612,  0.0425],\n",
      "        [-0.7080,  0.0501],\n",
      "        [-1.0041,  0.0279],\n",
      "        [-0.5918,  0.0703],\n",
      "        [-0.6607,  0.0384],\n",
      "        [-0.6148,  0.0580],\n",
      "        [-0.7639,  0.0691],\n",
      "        [-0.7021,  0.0127],\n",
      "        [-0.4781,  0.0388],\n",
      "        [-0.7034,  0.0390],\n",
      "        [-0.6869,  0.0180],\n",
      "        [-0.8000,  0.0324],\n",
      "        [-0.8857,  0.0345],\n",
      "        [-0.8634,  0.0390],\n",
      "        [-0.8058,  0.0206],\n",
      "        [-0.6657,  0.0549],\n",
      "        [-0.7729,  0.0581],\n",
      "        [-0.7819,  0.0135],\n",
      "        [-0.3576,  0.0274],\n",
      "        [-0.7855,  0.0155],\n",
      "        [-0.7792,  0.0551],\n",
      "        [-0.5121,  0.0390],\n",
      "        [-0.7464,  0.0205],\n",
      "        [-0.4104,  0.0282],\n",
      "        [-0.5865,  0.0082],\n",
      "        [-0.8719,  0.0170]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.0000, 0.0000],\n",
      "        [0.9821, 1.0000],\n",
      "        [0.3079, 0.0000],\n",
      "        [0.0314, 0.0000],\n",
      "        [0.4540, 1.0000],\n",
      "        [0.2844, 0.0000],\n",
      "        [0.7279, 1.0000],\n",
      "        [0.2182, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3908, 0.0000],\n",
      "        [0.7381, 1.0000],\n",
      "        [0.3172, 0.0000],\n",
      "        [0.7872, 1.0000],\n",
      "        [0.1235, 0.0000],\n",
      "        [0.2926, 0.0000],\n",
      "        [0.5375, 1.0000],\n",
      "        [0.3612, 0.0000],\n",
      "        [0.5753, 1.0000],\n",
      "        [0.4753, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5811, 1.0000],\n",
      "        [0.4175, 0.0000],\n",
      "        [0.2272, 0.0000],\n",
      "        [0.6894, 1.0000],\n",
      "        [0.3197, 0.0000],\n",
      "        [0.1845, 0.0000],\n",
      "        [0.0608, 0.0000],\n",
      "        [0.7694, 1.0000],\n",
      "        [0.2924, 0.0000],\n",
      "        [0.5718, 1.0000],\n",
      "        [0.6056, 1.0000],\n",
      "        [0.3810, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/3357 [00:04<08:43,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.3023,  0.0185],\n",
      "        [-0.5212,  0.0602],\n",
      "        [-0.3234,  0.0535],\n",
      "        [-0.3110,  0.0711],\n",
      "        [-0.7713,  0.0267],\n",
      "        [-0.3651,  0.0208],\n",
      "        [-0.5791,  0.0221],\n",
      "        [-0.2916,  0.0246],\n",
      "        [-0.3340,  0.0489],\n",
      "        [-0.4393,  0.0248],\n",
      "        [-0.3709,  0.0255],\n",
      "        [-0.6239,  0.0401],\n",
      "        [-0.3093,  0.0285],\n",
      "        [-0.8158,  0.0030],\n",
      "        [-0.3463,  0.0401],\n",
      "        [-0.3316,  0.0464],\n",
      "        [-0.8003,  0.0118],\n",
      "        [-0.4360,  0.0397],\n",
      "        [-0.3845,  0.0337],\n",
      "        [-0.2973,  0.0663],\n",
      "        [-0.2925,  0.0304],\n",
      "        [-0.8379,  0.0248],\n",
      "        [-0.2429,  0.0515],\n",
      "        [-0.4923,  0.0202],\n",
      "        [-0.4764,  0.0107],\n",
      "        [-0.9179,  0.0274],\n",
      "        [-0.4575,  0.0632],\n",
      "        [-0.4913,  0.0288],\n",
      "        [-0.5339,  0.0355],\n",
      "        [-0.2700,  0.0221],\n",
      "        [-0.3118,  0.0378],\n",
      "        [-0.4645,  0.0308]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.5084, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6566, 1.0000],\n",
      "        [0.1746, 0.0000],\n",
      "        [0.0381, 0.0000],\n",
      "        [0.7284, 1.0000],\n",
      "        [0.7256, 1.0000],\n",
      "        [0.1912, 0.0000],\n",
      "        [0.4220, 0.0000],\n",
      "        [0.6400, 1.0000],\n",
      "        [0.2856, 0.0000],\n",
      "        [0.3325, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4008, 0.0000],\n",
      "        [0.3981, 0.0000],\n",
      "        [0.5916, 1.0000],\n",
      "        [0.2372, 0.0000],\n",
      "        [0.5615, 1.0000],\n",
      "        [0.3584, 0.0000],\n",
      "        [0.0528, 0.0000],\n",
      "        [0.5140, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.8985, 1.0000],\n",
      "        [0.5656, 1.0000],\n",
      "        [0.3130, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7561, 1.0000],\n",
      "        [0.2002, 0.0000],\n",
      "        [0.0130, 0.0000],\n",
      "        [0.4107, 0.0000],\n",
      "        [0.5335, 1.0000],\n",
      "        [0.2485, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-4.1894e-01,  3.8035e-02],\n",
      "        [-3.1258e-01,  3.8311e-02],\n",
      "        [-4.2120e-01,  2.8933e-02],\n",
      "        [-9.1405e-01,  5.2777e-02],\n",
      "        [-2.9711e-01,  3.3003e-02],\n",
      "        [-2.6814e-01, -7.7187e-05],\n",
      "        [-3.6986e-01,  1.4372e-02],\n",
      "        [-6.9307e-01,  5.5430e-02],\n",
      "        [-5.2407e-01,  4.1201e-02],\n",
      "        [-4.9121e-01,  5.5137e-02],\n",
      "        [-5.4852e-01,  3.0420e-02],\n",
      "        [-3.3639e-01,  4.6914e-02],\n",
      "        [-3.5641e-01,  4.6785e-02],\n",
      "        [-3.4897e-01,  3.9879e-02],\n",
      "        [-3.6587e-01,  3.5098e-02],\n",
      "        [-4.3023e-01,  5.6069e-02],\n",
      "        [-3.5997e-01,  4.0484e-02],\n",
      "        [-2.9554e-01,  6.0902e-02],\n",
      "        [-7.7781e-01,  5.4931e-02],\n",
      "        [-3.6925e-01,  4.3195e-02],\n",
      "        [-3.2923e-01,  4.4457e-02],\n",
      "        [-2.9907e-01,  3.7356e-02],\n",
      "        [-3.3598e-01,  5.2096e-02],\n",
      "        [-3.7355e-01,  2.7388e-02],\n",
      "        [-8.4305e-01,  2.5431e-03],\n",
      "        [-3.5989e-01,  5.4426e-02],\n",
      "        [-3.3459e-01,  5.0677e-02],\n",
      "        [-8.2159e-01,  4.1877e-02],\n",
      "        [-8.4312e-01,  3.2539e-02],\n",
      "        [-4.2452e-01,  2.5850e-02],\n",
      "        [-3.5585e-01,  5.7266e-02],\n",
      "        [-8.4150e-01, -2.2281e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.4407, 1.0000],\n",
      "        [0.4653, 1.0000],\n",
      "        [0.0641, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7086, 1.0000],\n",
      "        [0.2622, 0.0000],\n",
      "        [0.1975, 0.0000],\n",
      "        [0.3074, 0.0000],\n",
      "        [0.4222, 0.0000],\n",
      "        [0.0176, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6896, 1.0000],\n",
      "        [0.6060, 1.0000],\n",
      "        [0.2674, 0.0000],\n",
      "        [0.8985, 1.0000],\n",
      "        [0.8914, 1.0000],\n",
      "        [0.4270, 1.0000],\n",
      "        [0.3547, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7846, 1.0000],\n",
      "        [0.7599, 1.0000],\n",
      "        [0.9804, 1.0000],\n",
      "        [0.3173, 0.0000],\n",
      "        [0.2134, 0.0000],\n",
      "        [0.6614, 1.0000],\n",
      "        [0.1705, 0.0000],\n",
      "        [0.0163, 0.0000],\n",
      "        [0.7629, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6578, 1.0000],\n",
      "        [0.1896, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/3357 [00:04<08:42,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-1.0877e+00, -2.4385e-02],\n",
      "        [-1.0324e+00, -1.3300e-02],\n",
      "        [-4.1143e-01,  5.2666e-02],\n",
      "        [-6.2186e-01,  7.2208e-02],\n",
      "        [-1.0954e+00,  1.2759e-02],\n",
      "        [-6.0484e-01,  4.0316e-02],\n",
      "        [-8.0355e-01,  4.0994e-02],\n",
      "        [-2.9846e-01,  5.3263e-02],\n",
      "        [-2.4524e-01,  1.9800e-02],\n",
      "        [-8.8902e-01,  8.9322e-03],\n",
      "        [-3.6031e-01,  1.5256e-02],\n",
      "        [-3.5830e-01,  1.0945e-02],\n",
      "        [-8.6575e-01,  2.5545e-02],\n",
      "        [-3.7970e-01,  2.6848e-02],\n",
      "        [-5.1386e-01,  6.2500e-02],\n",
      "        [-1.1357e+00, -2.0193e-03],\n",
      "        [-9.7070e-01,  7.8983e-03],\n",
      "        [-9.3929e-01,  8.2940e-03],\n",
      "        [-3.1166e-01,  4.2536e-02],\n",
      "        [-3.2206e-01,  3.0828e-02],\n",
      "        [-2.7157e-01,  2.8261e-02],\n",
      "        [-2.9005e-01,  4.6108e-02],\n",
      "        [-9.7289e-01,  3.5500e-02],\n",
      "        [-1.1334e+00,  1.0614e-03],\n",
      "        [-8.1815e-01,  4.2321e-02],\n",
      "        [-4.2052e-01,  7.2315e-02],\n",
      "        [-6.3685e-01, -8.0116e-03],\n",
      "        [-2.9179e-01,  2.6518e-02],\n",
      "        [-2.9836e-01,  4.3926e-02],\n",
      "        [-3.0497e-01,  3.5361e-02],\n",
      "        [-5.9232e-01,  2.3473e-02],\n",
      "        [-6.4998e-01,  5.7481e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2265, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5552, 1.0000],\n",
      "        [0.1815, 0.0000],\n",
      "        [0.3808, 0.0000],\n",
      "        [0.3057, 0.0000],\n",
      "        [0.1627, 0.0000],\n",
      "        [0.0968, 0.0000],\n",
      "        [0.4095, 0.0000],\n",
      "        [0.2115, 0.0000],\n",
      "        [0.0485, 0.0000],\n",
      "        [0.4263, 1.0000],\n",
      "        [0.2382, 0.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0503, 0.0000],\n",
      "        [0.1183, 0.0000],\n",
      "        [0.7741, 1.0000],\n",
      "        [0.5776, 1.0000],\n",
      "        [0.8526, 1.0000],\n",
      "        [0.1314, 0.0000],\n",
      "        [0.1634, 0.0000],\n",
      "        [0.4762, 1.0000],\n",
      "        [0.3781, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3762, 0.0000],\n",
      "        [0.7592, 1.0000],\n",
      "        [0.5811, 1.0000],\n",
      "        [0.6415, 1.0000],\n",
      "        [0.6367, 1.0000],\n",
      "        [0.7032, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-0.2422,  0.0470],\n",
      "        [-0.8853,  0.0025],\n",
      "        [-0.9385,  0.0512],\n",
      "        [-0.8499,  0.0533],\n",
      "        [-0.4982,  0.0410],\n",
      "        [-0.9781,  0.0506],\n",
      "        [-1.0527,  0.0422],\n",
      "        [-0.5135,  0.0165],\n",
      "        [-0.8049,  0.0545],\n",
      "        [-0.4187,  0.0600],\n",
      "        [-0.3023,  0.0330],\n",
      "        [-1.2035,  0.0395],\n",
      "        [-0.4718,  0.0340],\n",
      "        [-0.2872,  0.0249],\n",
      "        [-1.3986,  0.0274],\n",
      "        [-0.9229,  0.0382],\n",
      "        [-0.8724,  0.0642],\n",
      "        [-1.0419,  0.0033],\n",
      "        [-1.4640,  0.0457],\n",
      "        [-1.1573, -0.0130],\n",
      "        [-0.3119,  0.0163],\n",
      "        [-0.2398,  0.0608],\n",
      "        [-0.4065,  0.0558],\n",
      "        [-1.3930, -0.0122],\n",
      "        [-1.0678,  0.0101],\n",
      "        [-1.3459,  0.0365],\n",
      "        [-1.2342,  0.0191],\n",
      "        [-0.5192,  0.0197],\n",
      "        [-0.3488, -0.0017],\n",
      "        [-0.1914,  0.0342],\n",
      "        [-1.1211,  0.0131],\n",
      "        [-0.9267,  0.0395]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.5862, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2342, 0.0000],\n",
      "        [0.8631, 1.0000],\n",
      "        [0.1061, 0.0000],\n",
      "        [0.4689, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1534, 0.0000],\n",
      "        [0.6804, 1.0000],\n",
      "        [0.2626, 0.0000],\n",
      "        [0.1204, 0.0000],\n",
      "        [0.1823, 0.0000],\n",
      "        [0.1080, 0.0000],\n",
      "        [0.7859, 1.0000],\n",
      "        [0.1656, 0.0000],\n",
      "        [0.3942, 0.0000],\n",
      "        [0.2874, 0.0000],\n",
      "        [0.1374, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2476, 0.0000],\n",
      "        [0.4185, 0.0000],\n",
      "        [0.3230, 0.0000],\n",
      "        [0.1536, 0.0000],\n",
      "        [0.1934, 0.0000],\n",
      "        [0.6207, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1324, 0.0000],\n",
      "        [0.6562, 1.0000],\n",
      "        [0.6436, 1.0000],\n",
      "        [0.0668, 0.0000],\n",
      "        [0.2920, 0.0000],\n",
      "        [0.5011, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/3357 [00:04<08:42,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-0.1602,  0.0310],\n",
      "        [-0.1857,  0.0191],\n",
      "        [-0.4886,  0.0303],\n",
      "        [-0.6335, -0.0052],\n",
      "        [-1.3167,  0.0443],\n",
      "        [-0.2269,  0.0125],\n",
      "        [-0.6388,  0.0419],\n",
      "        [-0.3198,  0.0583],\n",
      "        [-0.2218,  0.0298],\n",
      "        [-0.6956,  0.0451],\n",
      "        [-0.1524,  0.0201],\n",
      "        [-0.2757,  0.0668],\n",
      "        [-0.2892,  0.0595],\n",
      "        [-0.7255,  0.0964],\n",
      "        [-0.1848,  0.0580],\n",
      "        [-1.2768,  0.0469],\n",
      "        [-0.4842,  0.0234],\n",
      "        [-0.2658,  0.0751],\n",
      "        [-0.4488,  0.0566],\n",
      "        [-0.1927,  0.0123],\n",
      "        [-0.2098,  0.0239],\n",
      "        [-0.2487,  0.0439],\n",
      "        [-0.1632, -0.0026],\n",
      "        [-1.4753,  0.0199],\n",
      "        [-0.2170,  0.0195],\n",
      "        [-0.2172,  0.0516],\n",
      "        [-0.2690,  0.0220],\n",
      "        [-0.1719,  0.0229],\n",
      "        [-0.6474,  0.0468],\n",
      "        [-1.1162,  0.0505],\n",
      "        [-1.1321,  0.0430],\n",
      "        [-0.2321,  0.0400]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.0880, 0.0000],\n",
      "        [0.5886, 1.0000],\n",
      "        [0.0337, 0.0000],\n",
      "        [0.1844, 0.0000],\n",
      "        [0.0768, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1670, 0.0000],\n",
      "        [0.5632, 1.0000],\n",
      "        [0.5973, 1.0000],\n",
      "        [0.1398, 0.0000],\n",
      "        [0.7085, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2904, 0.0000],\n",
      "        [0.2721, 0.0000],\n",
      "        [0.1674, 0.0000],\n",
      "        [0.0242, 0.0000],\n",
      "        [0.2105, 0.0000],\n",
      "        [0.7906, 1.0000],\n",
      "        [0.1872, 0.0000],\n",
      "        [0.1690, 0.0000],\n",
      "        [0.5616, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4223, 0.0000],\n",
      "        [0.2687, 0.0000],\n",
      "        [0.6997, 1.0000],\n",
      "        [0.9137, 1.0000],\n",
      "        [0.4950, 1.0000],\n",
      "        [0.0671, 0.0000],\n",
      "        [0.3357, 0.0000],\n",
      "        [0.9187, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-1.9531,  0.0173],\n",
      "        [-1.1741,  0.0442],\n",
      "        [-1.7860,  0.0262],\n",
      "        [-1.3399,  0.0306],\n",
      "        [-0.7884,  0.0727],\n",
      "        [-2.0209,  0.0156],\n",
      "        [-1.4902,  0.0148],\n",
      "        [-0.3733,  0.0480],\n",
      "        [-1.2784,  0.0720],\n",
      "        [-0.5341,  0.0609],\n",
      "        [-1.9141,  0.0187],\n",
      "        [-1.7065,  0.0066],\n",
      "        [-1.0599,  0.0653],\n",
      "        [-1.5905,  0.0489],\n",
      "        [-1.9968,  0.0141],\n",
      "        [-0.7274,  0.0555],\n",
      "        [-1.8302,  0.0205],\n",
      "        [-1.8114,  0.0338],\n",
      "        [-0.6453,  0.0476],\n",
      "        [-1.9038,  0.0488],\n",
      "        [-1.0992,  0.0234],\n",
      "        [-1.7173,  0.0509],\n",
      "        [-1.5526, -0.0195],\n",
      "        [-1.4833,  0.0481],\n",
      "        [-1.6011,  0.0048],\n",
      "        [-1.9488, -0.0077],\n",
      "        [-1.9113,  0.0131],\n",
      "        [-1.6856,  0.0168],\n",
      "        [-1.8598,  0.0257],\n",
      "        [-1.7739,  0.0092],\n",
      "        [-0.7374,  0.0268],\n",
      "        [-1.6421,  0.0299]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.3605, 0.0000],\n",
      "        [0.5550, 1.0000],\n",
      "        [0.3625, 0.0000],\n",
      "        [0.1203, 0.0000],\n",
      "        [0.0625, 0.0000],\n",
      "        [0.2184, 0.0000],\n",
      "        [0.6273, 1.0000],\n",
      "        [0.3872, 0.0000],\n",
      "        [0.7783, 1.0000],\n",
      "        [0.3589, 0.0000],\n",
      "        [0.7259, 1.0000],\n",
      "        [0.2269, 0.0000],\n",
      "        [0.7231, 1.0000],\n",
      "        [0.5147, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2154, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3093, 0.0000],\n",
      "        [0.3102, 0.0000],\n",
      "        [0.7711, 1.0000],\n",
      "        [0.2095, 0.0000],\n",
      "        [0.2443, 0.0000],\n",
      "        [0.5713, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5985, 1.0000],\n",
      "        [0.3869, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.2294, 0.0000],\n",
      "        [0.0130, 0.0000],\n",
      "        [0.4415, 1.0000],\n",
      "        [0.6920, 1.0000],\n",
      "        [0.3302, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/3357 [00:05<08:40,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[-8.4876e-01,  5.8104e-02],\n",
      "        [-1.4998e+00,  3.2309e-02],\n",
      "        [-5.4227e-01,  4.6300e-02],\n",
      "        [-6.7193e-01,  5.8532e-02],\n",
      "        [-1.2012e+00,  4.7167e-02],\n",
      "        [-9.4312e-01,  3.0694e-02],\n",
      "        [-5.1049e-01,  4.7769e-02],\n",
      "        [-7.9704e-01,  4.9264e-02],\n",
      "        [-3.7617e-01,  4.1376e-02],\n",
      "        [-5.1260e-01,  3.4887e-02],\n",
      "        [-1.6202e+00,  4.4857e-02],\n",
      "        [-3.7344e-01,  1.5305e-02],\n",
      "        [-1.1940e+00,  3.6769e-02],\n",
      "        [-4.4168e-01,  6.3205e-02],\n",
      "        [-5.1071e-01,  5.5009e-02],\n",
      "        [-1.2980e+00,  4.1913e-02],\n",
      "        [-4.5674e-01,  4.8530e-02],\n",
      "        [-1.3260e+00, -2.4155e-05],\n",
      "        [-3.7468e-01,  1.7963e-02],\n",
      "        [-4.4650e-01,  4.9225e-02],\n",
      "        [-3.0439e-01,  8.3782e-03],\n",
      "        [-7.8669e-01,  4.6275e-02],\n",
      "        [-1.2723e+00,  2.2328e-02],\n",
      "        [-2.9756e-01,  2.7865e-02],\n",
      "        [-8.6335e-01,  4.9397e-02],\n",
      "        [-3.1153e-01,  3.8824e-02],\n",
      "        [-5.4877e-01,  8.3997e-03],\n",
      "        [-4.2539e-01,  2.9710e-02],\n",
      "        [-1.3065e+00,  5.0242e-02],\n",
      "        [-1.4730e+00,  4.8489e-02],\n",
      "        [-1.5054e+00,  2.6452e-02],\n",
      "        [-1.3277e+00,  3.2259e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.2804, 0.0000],\n",
      "        [0.2646, 0.0000],\n",
      "        [0.1569, 0.0000],\n",
      "        [0.0634, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7012, 1.0000],\n",
      "        [0.2604, 0.0000],\n",
      "        [0.2027, 0.0000],\n",
      "        [0.6973, 1.0000],\n",
      "        [0.4847, 1.0000],\n",
      "        [0.0981, 0.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.7542, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5606, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5702, 1.0000],\n",
      "        [0.0641, 0.0000],\n",
      "        [0.3391, 0.0000],\n",
      "        [0.4468, 1.0000],\n",
      "        [0.5495, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5641, 1.0000],\n",
      "        [0.6001, 1.0000],\n",
      "        [0.1279, 0.0000],\n",
      "        [0.9178, 1.0000],\n",
      "        [0.8516, 1.0000],\n",
      "        [0.4220, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4735, 1.0000],\n",
      "        [0.2201, 0.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-1.9293e-01,  2.9544e-02],\n",
      "        [-2.2589e-01,  3.9425e-02],\n",
      "        [-8.1524e-01,  3.6387e-02],\n",
      "        [-3.0507e-01,  1.0587e-02],\n",
      "        [-2.4075e-01,  1.5428e-02],\n",
      "        [-6.8244e-01,  4.1263e-02],\n",
      "        [-9.6713e-01,  2.2243e-02],\n",
      "        [-1.7185e-01,  7.2195e-05],\n",
      "        [-1.4072e-01,  6.5787e-03],\n",
      "        [-5.9639e-01,  2.0978e-02],\n",
      "        [-2.9260e-01,  1.9507e-02],\n",
      "        [-1.8602e-01,  3.8251e-04],\n",
      "        [-4.4139e-01,  3.3526e-02],\n",
      "        [-7.9312e-01,  2.7947e-02],\n",
      "        [-2.2343e-01,  1.6261e-02],\n",
      "        [-9.0890e-01,  4.0673e-02],\n",
      "        [-5.9610e-01,  3.6008e-02],\n",
      "        [-1.0759e+00,  7.3171e-02],\n",
      "        [-1.5034e-01,  2.2735e-03],\n",
      "        [-1.4565e-01,  6.3593e-03],\n",
      "        [-9.8979e-01,  3.8572e-02],\n",
      "        [-1.0053e+00,  4.6465e-02],\n",
      "        [-4.9611e-01,  2.5291e-02],\n",
      "        [-5.4548e-01,  2.1872e-02],\n",
      "        [-1.2421e-01,  1.9172e-02],\n",
      "        [-1.0212e+00,  1.8468e-02],\n",
      "        [-2.3123e-01,  2.8110e-02],\n",
      "        [-1.1215e+00,  5.1562e-02],\n",
      "        [-4.8981e-01,  3.7090e-02],\n",
      "        [-2.0168e-01,  2.0998e-02],\n",
      "        [-1.3155e+00,  3.0874e-02],\n",
      "        [-4.9308e-01,  5.7568e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.6256, 1.0000],\n",
      "        [0.7550, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1479, 0.0000],\n",
      "        [0.1650, 0.0000],\n",
      "        [0.4060, 0.0000],\n",
      "        [0.3970, 0.0000],\n",
      "        [0.5981, 1.0000],\n",
      "        [0.5159, 1.0000],\n",
      "        [0.4189, 0.0000],\n",
      "        [0.3574, 0.0000],\n",
      "        [0.8216, 1.0000],\n",
      "        [0.4425, 1.0000],\n",
      "        [0.0477, 0.0000],\n",
      "        [0.3303, 0.0000],\n",
      "        [0.4489, 1.0000],\n",
      "        [0.7507, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.9046, 1.0000],\n",
      "        [0.8819, 1.0000],\n",
      "        [0.6475, 1.0000],\n",
      "        [0.3528, 0.0000],\n",
      "        [0.6083, 1.0000],\n",
      "        [0.5753, 1.0000],\n",
      "        [0.8981, 1.0000],\n",
      "        [0.2721, 0.0000],\n",
      "        [0.2569, 0.0000],\n",
      "        [0.0356, 0.0000],\n",
      "        [0.2388, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0851, 0.0000],\n",
      "        [0.7330, 1.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/3357 [00:05<08:40,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n",
      "(tensor([[ 0.0306, -0.0269],\n",
      "        [-0.2156,  0.0338],\n",
      "        [ 0.0081, -0.0310],\n",
      "        [ 0.0207, -0.0242],\n",
      "        [ 0.0130, -0.0074],\n",
      "        [-0.0820, -0.0010],\n",
      "        [ 0.0283, -0.0413],\n",
      "        [-0.3691,  0.0399],\n",
      "        [ 0.0016,  0.0182],\n",
      "        [ 0.0253, -0.0202],\n",
      "        [-0.2184,  0.0056],\n",
      "        [ 0.0188, -0.0025],\n",
      "        [-0.0381, -0.0444],\n",
      "        [-0.0159, -0.0174],\n",
      "        [-0.1366,  0.0344],\n",
      "        [ 0.0199, -0.0268],\n",
      "        [-0.0279,  0.0059],\n",
      "        [-0.0009, -0.0036],\n",
      "        [-0.3083,  0.0232],\n",
      "        [-0.0184, -0.0138],\n",
      "        [ 0.0281, -0.0408],\n",
      "        [-0.1600,  0.0387],\n",
      "        [-0.2098,  0.0129],\n",
      "        [-0.0335, -0.0328],\n",
      "        [ 0.0021, -0.0193],\n",
      "        [-0.0780, -0.0106],\n",
      "        [-0.0264, -0.0110],\n",
      "        [-0.0530, -0.0205],\n",
      "        [ 0.0333, -0.0115],\n",
      "        [ 0.0429, -0.0167],\n",
      "        [-0.0462, -0.0209],\n",
      "        [-0.0304, -0.0123]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.6201, 1.0000],\n",
      "        [0.0974, 0.0000],\n",
      "        [0.7646, 1.0000],\n",
      "        [0.6201, 1.0000],\n",
      "        [0.0808, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7025, 1.0000],\n",
      "        [0.1810, 0.0000],\n",
      "        [0.1671, 0.0000],\n",
      "        [0.1715, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5060, 1.0000],\n",
      "        [0.4062, 0.0000],\n",
      "        [0.4787, 1.0000],\n",
      "        [0.8056, 1.0000],\n",
      "        [0.2859, 0.0000],\n",
      "        [0.8601, 1.0000],\n",
      "        [0.7002, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6127, 1.0000],\n",
      "        [0.2092, 0.0000],\n",
      "        [0.1373, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1024, 0.0000],\n",
      "        [0.5426, 1.0000],\n",
      "        [0.1056, 0.0000],\n",
      "        [0.3760, 0.0000],\n",
      "        [0.4340, 1.0000],\n",
      "        [0.5581, 1.0000],\n",
      "        [0.6220, 1.0000],\n",
      "        [0.2904, 0.0000],\n",
      "        [0.6142, 1.0000]], device='cuda:0'))\n",
      "entro\n",
      "(tensor([[-1.7554e-01, -6.4162e-03],\n",
      "        [-2.4443e-01,  5.8675e-03],\n",
      "        [-3.1845e-01,  1.8568e-02],\n",
      "        [-9.1280e-01,  4.5756e-02],\n",
      "        [-7.7792e-02,  1.4642e-02],\n",
      "        [-1.1051e-01, -5.2667e-03],\n",
      "        [-1.4299e-01,  2.9130e-03],\n",
      "        [-1.2049e-01, -5.3650e-03],\n",
      "        [-9.8304e-01,  6.6752e-02],\n",
      "        [-4.2407e-01,  4.4471e-02],\n",
      "        [-4.4409e-01,  4.0725e-02],\n",
      "        [-5.9482e-01,  2.1714e-02],\n",
      "        [-3.2463e-01, -4.6576e-03],\n",
      "        [-1.8765e-01, -1.4122e-03],\n",
      "        [-1.5893e-01,  1.6002e-02],\n",
      "        [-1.4345e-01, -1.8829e-02],\n",
      "        [-6.2544e-01,  2.6747e-02],\n",
      "        [-1.8627e-01, -9.6056e-04],\n",
      "        [-1.4960e-01, -1.7976e-03],\n",
      "        [-2.0626e-01,  1.1177e-02],\n",
      "        [-3.6490e-01,  1.9802e-02],\n",
      "        [-1.4838e-01, -2.1683e-04],\n",
      "        [-3.4518e-01, -3.4302e-03],\n",
      "        [-1.9245e-01,  9.5211e-03],\n",
      "        [-2.3774e-01,  9.5640e-03],\n",
      "        [-1.9229e-01,  1.1279e-02],\n",
      "        [-1.4469e-01, -9.1774e-03],\n",
      "        [-1.2475e-01,  4.3175e-03],\n",
      "        [-1.5915e-01, -1.6359e-02],\n",
      "        [-1.7756e-01,  5.9524e-03],\n",
      "        [-6.2219e-01,  3.0805e-02],\n",
      "        [-8.4081e-01,  4.8177e-02]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[0.5834, 1.0000],\n",
      "        [0.2664, 0.0000],\n",
      "        [0.4246, 0.0000],\n",
      "        [0.4951, 1.0000],\n",
      "        [0.3673, 0.0000],\n",
      "        [0.6562, 1.0000],\n",
      "        [0.6881, 1.0000],\n",
      "        [0.6707, 1.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7421, 1.0000],\n",
      "        [0.3128, 0.0000],\n",
      "        [0.6844, 1.0000],\n",
      "        [0.1011, 0.0000],\n",
      "        [0.2810, 0.0000],\n",
      "        [0.2539, 0.0000],\n",
      "        [0.7479, 1.0000],\n",
      "        [0.5088, 1.0000],\n",
      "        [0.1935, 0.0000],\n",
      "        [0.7935, 1.0000],\n",
      "        [0.3312, 0.0000],\n",
      "        [0.4795, 1.0000],\n",
      "        [0.6503, 1.0000],\n",
      "        [0.4102, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.1022, 0.0000],\n",
      "        [0.5243, 1.0000],\n",
      "        [0.0726, 0.0000],\n",
      "        [0.3755, 0.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [0.2069, 0.0000],\n",
      "        [0.1424, 0.0000]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/3357 [00:05<11:34,  4.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vicente/projects/neoantigen/BERTMHC/bertmhc/dataloader.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vicente/projects/neoantigen/BERTMHC/bertmhc/dataloader.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vicente/projects/neoantigen/BERTMHC/bertmhc/dataloader.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vicente/projects/neoantigen/BERTMHC/bertmhc/dataloader.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     train_metrics \u001b[39m=\u001b[39m train(model, optimizer, train_data, device, aff_criterion, mass_criterion, alpha, scheduler)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vicente/projects/neoantigen/BERTMHC/bertmhc/dataloader.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     eval_metrics \u001b[39m=\u001b[39m evaluate(model, val_data, device, aff_criterion, mass_criterion, alpha)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vicente/projects/neoantigen/BERTMHC/bertmhc/dataloader.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     eval_metrics[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_metrics\n",
      "File \u001b[0;32m~/projects/neoantigen/BERTMHC/bertmhc/utils_model.py:314\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_data, device, aff_criterion, mass_criterion, alpha, scheduler)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m0.5\u001b[39m)\n\u001b[0;32m--> 314\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scheduler, LambdaLR):\n\u001b[1;32m    316\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch11/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch11/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch11/lib/python3.8/site-packages/torch/optim/sgd.py:144\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 144\u001b[0m F\u001b[39m.\u001b[39;49msgd(params_with_grad,\n\u001b[1;32m    145\u001b[0m       d_p_list,\n\u001b[1;32m    146\u001b[0m       momentum_buffer_list,\n\u001b[1;32m    147\u001b[0m       weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    148\u001b[0m       momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    149\u001b[0m       lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    150\u001b[0m       dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    151\u001b[0m       nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    152\u001b[0m       maximize\u001b[39m=\u001b[39;49mmaximize,)\n\u001b[1;32m    154\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch11/lib/python3.8/site-packages/torch/optim/_functional.py:186\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    184\u001b[0m     momentum_buffer_list[i] \u001b[39m=\u001b[39m buf\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     buf\u001b[39m.\u001b[39;49mmul_(momentum)\u001b[39m.\u001b[39madd_(d_p, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m dampening)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m nesterov:\n\u001b[1;32m    189\u001b[0m     d_p \u001b[39m=\u001b[39m d_p\u001b[39m.\u001b[39madd(buf, alpha\u001b[39m=\u001b[39mmomentum)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.15\n",
    "w_pos = 1.0 # mass positive weight\n",
    "save = \"TRAIN_4_bertmhc_model.pt\"\n",
    "alpha = 0.0 # alpha weight on mass loss, affinity loss weight with 1-alpha\n",
    "patience = 5 # Earlystopping patience\n",
    "metric = 'val_auc' # validation metric, default auc\n",
    "\n",
    "aff_criterion = nn.BCEWithLogitsLoss()\n",
    "w_pos = torch.tensor([w_pos]).to(device)\n",
    "mass_criterion = nn.BCEWithLogitsLoss(pos_weight=w_pos, reduction='none')\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=2, min_lr=1e-4, factor=0.1)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, saveto=save)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Training epoch {}\".format(epoch))\n",
    "    train_metrics = train(model, optimizer, train_data, device, aff_criterion, mass_criterion, alpha, scheduler)\n",
    "    eval_metrics = evaluate(model, val_data, device, aff_criterion, mass_criterion, alpha)\n",
    "    eval_metrics['train_loss'] = train_metrics\n",
    "    logs = eval_metrics\n",
    "\n",
    "    scheduler.step(logs.get(metric))\n",
    "    logging.info('Sample dict log: %s' % logs)\n",
    "\n",
    "    # callbacks\n",
    "    early_stopping(-logs.get(metric), model, optimizer)\n",
    "    if early_stopping.early_stop or logs.get(metric) <= 0:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate dimensiones de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6, 56, 764])\n",
      "torch.Size([32, 6, 28, 382])\n",
      "torch.Size([32, 16, 24, 378])\n",
      "torch.Size([32, 16, 12, 189])\n",
      "torch.Size([32, 36288])\n",
      "torch.Size([32, 10000])\n",
      "torch.Size([32, 500])\n",
      "tensor([[0.0018, 0.0019, 0.0023,  ..., 0.0021, 0.0021, 0.0020],\n",
      "        [0.0019, 0.0020, 0.0023,  ..., 0.0021, 0.0021, 0.0021],\n",
      "        [0.0018, 0.0020, 0.0023,  ..., 0.0021, 0.0022, 0.0020],\n",
      "        ...,\n",
      "        [0.0019, 0.0020, 0.0023,  ..., 0.0021, 0.0021, 0.0021],\n",
      "        [0.0019, 0.0020, 0.0023,  ..., 0.0021, 0.0021, 0.0021],\n",
      "        [0.0019, 0.0019, 0.0022,  ..., 0.0021, 0.0020, 0.0021]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23905/2800599566.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(n6(x))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# con una CNN 1d\n",
    "n = nn.Conv1d(60, 128, kernel_size=3)\n",
    "\n",
    "input = torch.randn(32, 60, 768) # embed de tape con batch size 32 [batch_size, dimx, dimy]\n",
    "output = n(input)\n",
    "#print(output)\n",
    "\n",
    "# con una CNN 2d\n",
    "n1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "n2 = nn.MaxPool2d(2, 2)  \n",
    "n3 = conv2 = nn.Conv2d(6, 16, 5) \n",
    "\n",
    "n4 = nn.Linear(16*12*189, 10000) \n",
    "n6 = nn.Linear(10000, 500)\n",
    "n7 = nn.Softmax()    \n",
    "\n",
    "input = torch.randn(32, 60, 768) # input desde tape model con 32 de batch size\n",
    "input = input.view(32, 1, 60, 768)\n",
    "\n",
    "#input = torch.randn(32, 1, 60, 768)\n",
    "x = F.relu(n1(input))           # [32, 1, 60, 768] -> [32, 6, 56, 764]\n",
    "print(x.shape)\n",
    "x = n2(x)                       # [32, 6, 56, 764] -> [32, 6, 28, 382]\n",
    "print(x.shape)\n",
    "x = F.relu(n3(x))               # [32, 6, 28, 382] -> [32, 16, 24, 378]\n",
    "print(x.shape)\n",
    "x = n2(x)                       # [32, 16, 24, 378] -> [32, 16, 12, 189]\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(-1, 16*12*189) \n",
    "print(x.shape)\n",
    "\n",
    "x = F.relu(n4(x))\n",
    "print(x.shape)\n",
    "output = F.softmax(n6(x))\n",
    "print(output.shape)\n",
    "#outputs = n7(x) \n",
    "#print(x.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 1])\n",
      "tensor([[[0.5482]],\n",
      "\n",
      "        [[0.4293]],\n",
      "\n",
      "        [[0.5503]],\n",
      "\n",
      "        [[0.4340]],\n",
      "\n",
      "        [[0.6277]],\n",
      "\n",
      "        [[0.5838]],\n",
      "\n",
      "        [[0.4624]],\n",
      "\n",
      "        [[0.6540]],\n",
      "\n",
      "        [[0.6292]],\n",
      "\n",
      "        [[0.8801]],\n",
      "\n",
      "        [[0.1949]],\n",
      "\n",
      "        [[0.4478]],\n",
      "\n",
      "        [[0.7024]],\n",
      "\n",
      "        [[0.7735]],\n",
      "\n",
      "        [[0.2155]],\n",
      "\n",
      "        [[0.3104]],\n",
      "\n",
      "        [[0.6967]],\n",
      "\n",
      "        [[0.4506]],\n",
      "\n",
      "        [[0.4824]],\n",
      "\n",
      "        [[0.4654]],\n",
      "\n",
      "        [[0.4646]],\n",
      "\n",
      "        [[0.4440]],\n",
      "\n",
      "        [[0.4283]],\n",
      "\n",
      "        [[0.4069]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.4635]],\n",
      "\n",
      "        [[0.7084]],\n",
      "\n",
      "        [[0.3120]],\n",
      "\n",
      "        [[0.4717]],\n",
      "\n",
      "        [[0.5794]],\n",
      "\n",
      "        [[0.4974]],\n",
      "\n",
      "        [[0.3781]]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "dropout     = nn.Dropout(0.2)\n",
    "linear      = nn.Linear(768, 1)\n",
    "sigmoid     = nn.Sigmoid()    \n",
    "\n",
    "input = torch.randn(32, 1, 768) \n",
    "\n",
    "out = dropout(input)   \n",
    "out = linear(out) \n",
    "out = sigmoid(out)         \n",
    "\n",
    "print(out.shape)\n",
    "print(out)\n",
    "\n",
    "from tape.models.modeling_utils import SimpleMLP\n",
    "logits = self.classify(average, targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils_model import EarlyStopping, MAData\n",
    "from tape import ProteinBertConfig\n",
    "from dataloader import BertDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "from bertmhc import BERTMHC\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils_model import train, evaluate\n",
    "\n",
    "def predict(data, model_path, output_path):\n",
    "    inp = data\n",
    "    config = ProteinBertConfig.from_pretrained('bert-base')\n",
    "    model = BERTMHC(config)\n",
    "    weights = torch.load(model_path)\n",
    "    \n",
    "    if list(weights.keys())[0].startswith('module.'):\n",
    "        weights = {k[7:]: v for k, v in weights.items() if k.startswith('module.')}\n",
    "    model.load_state_dict(weights)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    valset = BertDataset(inp,\n",
    "                         max_pep_len=24,\n",
    "                         train=False)\n",
    "    val_data = DataLoader(valset,\n",
    "                          batch_size=16,\n",
    "                          num_workers=16,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=valset.collate_fn)\n",
    "    pred = []\n",
    "    for batch in tqdm(val_data):\n",
    "        batch = {name: tensor.to(device)\n",
    "                 for name, tensor in batch.items()}\n",
    "        logits, _ = model(**batch)\n",
    "        pred.append(torch.sigmoid(logits).cpu().detach().numpy())\n",
    "    dt = pd.read_csv(inp)\n",
    "    pred = np.concatenate(pred)\n",
    "    \n",
    "    '''if args.task == 'binding':\n",
    "        dt['bertmhc_pred'] = pred[:,0]\n",
    "    else:\n",
    "        dt['bertmhc_pred'] = pred[:,1]'''\n",
    "    \n",
    "    dt['bertmhc_pred'] = pred[:,0]\n",
    "    dt.to_csv(output_path, index=None)\n",
    "    return dt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict del modelo TRAIN_3 de la forma igual a BERTMHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:18<00:00, 45.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dt_train_3 = predict(    data        =   \"../../dataset/netMHCIIpan3.2/test_mini.csv\", \n",
    "            model_path  =   \"TRAIN_3_bertmhc_model.pt\", \n",
    "            output_path =   \"train_3_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8066125549184601, 'precision': 0.8008178687638494, 'recall': 0.8001206157435652, 'fscore': 0.8004603694779975}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6595, 1277],\n",
       "       [1320, 4237]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "dt_train_3['pred'] = dt_train_3.apply(lambda row: (1 if row['bertmhc_pred'] > 0.426 else 0), axis=1)    # 0.807952937672202\n",
    "#dt_train_3['pred'] = dt_train_3.apply(lambda row: (1 if row['bertmhc_pred'] > 0.5 else 0), axis=1)     # 0.7962618214312309\n",
    "\n",
    "y_true_3 = dt_train_3['masslabel'].to_numpy()\n",
    "y_pred_3 = dt_train_3['pred'].to_numpy()\n",
    "acc = accuracy_score(y_true_3, y_pred_3)\n",
    "precision, recall, fscore, _ =  precision_recall_fscore_support(y_true_3, y_pred_3, average='macro')\n",
    "result_3 = {\"acc\":acc, \"precision\":precision, \"recall\":recall, \"fscore\":fscore }\n",
    "print(result_3)\n",
    "confusion_matrix(y_true_3, y_pred_3)\n",
    "#print(accuracy_score(y_true, y_pred, normalize=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict del modelo TRAIN_4 de la forma igual a BERTMHC pero con padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:18<00:00, 45.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dt_train_4 = predict(    data        =   \"../../dataset/netMHCIIpan3.2/test_mini.csv\", \n",
    "            model_path  =   \"TRAIN_4_bertmhc_model.pt\", \n",
    "            output_path =   \"train_4_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.7375083773922109, 'precision': 0.7352630171197421, 'recall': 0.7147436407387737, 'fscore': 0.7192116524243642}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6666, 1206],\n",
       "       [2319, 3238]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "dt_train_4['pred'] = dt_train_4.apply(lambda row: (1 if row['bertmhc_pred'] > 0.426 else 0), axis=1)    # 0.7375083773922109\n",
    "#dt_train_4['pred'] = dt_train_4.apply(lambda row: (1 if row['bertmhc_pred'] > 0.5 else 0), axis=1)       # 0.7178494303373296\n",
    "\n",
    "y_true_4 = dt_train_4['masslabel'].to_numpy()\n",
    "y_pred_4 = dt_train_4['pred'].to_numpy()\n",
    "acc = accuracy_score(y_true_4, y_pred_4)\n",
    "precision, recall, fscore, _ =  precision_recall_fscore_support(y_true_4, y_pred_4, average='macro')\n",
    "result_4 = {\"acc\":acc, \"precision\":precision, \"recall\":recall, \"fscore\":fscore }\n",
    "print(result_4)\n",
    "confusion_matrix(y_true_4, y_pred_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr_3, tpr_3, _ = metrics.roc_curve(y_true_3,  y_pred_3)\n",
    "auc_3 = metrics.roc_auc_score(y_true_3, y_pred_3)\n",
    "\n",
    "fpr_4, tpr_4, _ = metrics.roc_curve(y_true_4,  y_pred_4)\n",
    "auc_4 = metrics.roc_auc_score(y_true_4, y_pred_4)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr_3,tpr_3, label=\"BERTMHC, auc=\"+str(round(auc_3,3)))\n",
    "plt.plot(fpr_4,tpr_4, label=\"BERTMHC-pad, auc=\"+str(round(auc_4, 3)))\n",
    "plt.legend(loc=4)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "#plt.show()\n",
    "plt.savefig('roc_comparison.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.25\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# set height of bar\n",
    "IT = list(result_3.values())\n",
    "ECE = list(result_4.values())\n",
    " \n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(IT))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, IT, color ='dodgerblue', width = barWidth, label ='BERTMHC')\n",
    "plt.bar(br2, ECE, color ='lightgreen', width = barWidth, label ='BERTMHC-pad')\n",
    " \n",
    "# Adding Xticks\n",
    "plt.xlabel('Metrics',  fontsize = 15)\n",
    "plt.ylabel('Values', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(IT))],\n",
    "        ['Accuracy', 'Precision', 'Recall', 'f-score'])\n",
    " \n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig('metrics_comparison.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "706e3f9463f4659aea008cbeb97149de47ce197374eec6ebe341c89d29bb6fd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
